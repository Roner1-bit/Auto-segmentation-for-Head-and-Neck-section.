{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "segUnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It_8PqniBsTq",
        "outputId": "bab8cce0-8039-4f0c-9d7d-f832a3765dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QawvgeYEYaI8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate,Add\n",
        "import keras as Ks\n",
        "from keras.layers import Input\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import Precision, Recall, MeanIoU\n",
        "import cv2\n",
        "from skimage import io\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape, Permute\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
        "# import tensorflow as tf\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.merge import Multiply, Concatenate\n",
        "from keras.utils import np_utils\n",
        "# from keras.layers.pooling import MaxPoolingWithArgmax2D,MaxUnpooling2D\n",
        "# import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "# from Layer import  MaxUnpooling2D,MaxPoolingWithArgmax2D\n",
        "# import tensorflow_addons as tfa\n",
        "from tensorflow_addons.layers import MaxUnpooling2D\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, AveragePooling2D, Dense, Flatten\n",
        "from keras.layers import Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPoolingWithArgmax2D(Layer):\n",
        "    def __init__(self, pool_size=(2, 2), strides=(1, 1), padding='same', **kwargs):\n",
        "        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n",
        "        self.padding = padding\n",
        "        self.pool_size = pool_size\n",
        "        self.strides = strides\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        padding = self.padding\n",
        "        pool_size = self.pool_size\n",
        "        strides = self.strides\n",
        "        if K.backend() == 'tensorflow':\n",
        "            ksize = [1, pool_size[0], pool_size[1], 1]\n",
        "            padding = padding.upper()\n",
        "            strides = [1, strides[0], strides[1], 1]\n",
        "            output, argmax = K.tf.nn.max_pool_with_argmax(inputs, ksize=ksize, strides=strides, padding=padding)\n",
        "        else:\n",
        "            errmsg = '{} backend is not supported for layer {}'.format(K.backend(), type(self).__name__)\n",
        "            raise NotImplementedError(errmsg)\n",
        "        argmax = K.cast(argmax, K.floatx())\n",
        "        return [output, argmax]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        ratio = (1, 2, 2, 1)\n",
        "        output_shape = [dim // ratio[idx] if dim is not None else None for idx, dim in enumerate(input_shape)]\n",
        "        output_shape = tuple(output_shape)\n",
        "        return [output_shape, output_shape]\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return 2 * [None]\n",
        "\n",
        "\n",
        "# class MaxUnpooling2D(Layer):\n",
        "#     def __init__(self, size=(1, 1), **kwargs):\n",
        "#         super(MaxUnpooling2D, self).__init__(**kwargs)\n",
        "#         self.size = size\n",
        "\n",
        "#     def call(self, inputs, output_shape=None):\n",
        "#         updates, mask = inputs[0], inputs[1]\n",
        "#         with K.tf.variable_scope(self.name):\n",
        "#             mask = K.cast(mask, 'int32')\n",
        "#             input_shape = K.tf.shape(updates, out_type='int32')\n",
        "#             #  calculation new shape\n",
        "#             if output_shape is None:\n",
        "#                 output_shape = (input_shape[0], input_shape[1] * self.size[0], input_shape[2] * self.size[1], input_shape[3])\n",
        "#             self.output_shape1 = output_shape\n",
        "\n",
        "#             # calculation indices for batch, height, width and feature maps\n",
        "#             one_like_mask = K.ones_like(mask, dtype='int32')\n",
        "#             batch_shape = K.concatenate([[input_shape[0]], [1], [1], [1]], axis=0)\n",
        "#             batch_range = K.reshape(K.tf.range(output_shape[0], dtype='int32'), shape=batch_shape)\n",
        "#             b = one_like_mask * batch_range\n",
        "#             y = mask // (output_shape[2] * output_shape[3])\n",
        "#             x = (mask // output_shape[3]) % output_shape[2]\n",
        "#             feature_range = K.tf.range(output_shape[3], dtype='int32')\n",
        "#             f = one_like_mask * feature_range\n",
        "\n",
        "#             # transpose indices & reshape update values to one dimension\n",
        "#             updates_size = K.tf.size(updates)\n",
        "#             indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))\n",
        "#             values = K.reshape(updates, [updates_size])\n",
        "#             ret = K.tf.scatter_nd(indices, values, output_shape)\n",
        "#             return ret\n",
        "\n",
        "#     def compute_output_shape(self, input_shape):\n",
        "#         mask_shape = input_shape[1]\n",
        "#         return mask_shape[0], mask_shape[1] * self.size[0], mask_shape[2] * self.size[1], mask_shape[3]"
      ],
      "metadata": {
        "id": "-dpz3Odrc7Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGWPD-JSQ9pD",
        "outputId": "a0139a18-145d-41b9-8767-a1a38c212adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --no-cache-dir gdown --pre\n",
        "!gdown --id 1-2HGO0znF0JAsgZ_et5Cr_owKVxr_bKZ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioCsI4LEOFPK",
        "outputId": "e19fcd7b-10ce-461e-8961-e4631f57e337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14774 sha256=cb6872d59172c20b0080b850aeee8ae5f90914c6aa0636ea074b515dd9e39096\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c9ar_hhr/wheels/fb/c3/0e/c4d8ff8bfcb0461afff199471449f642179b74968c15b7a69c\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.2.2\n",
            "    Uninstalling gdown-4.2.2:\n",
            "      Successfully uninstalled gdown-4.2.2\n",
            "Successfully installed gdown-4.4.0\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-2HGO0znF0JAsgZ_et5Cr_owKVxr_bKZ\n",
            "To: /content/CT_Data.zip\n",
            "100% 624M/624M [00:04<00:00, 143MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "file_name=\"/content/CT_Data.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as ziip:\n",
        "  ziip.extractall()\n",
        "  print('woow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nernz1QdOWP4",
        "outputId": "53eed287-ca5a-4a2b-ef4e-efdb3497f71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "woow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_files = glob('/content/content/drive/MyDrive/CT_Data/Masks/*')\n",
        "len(mask_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QV-NzPMOzO6",
        "outputId": "4006358e-d7ec-4d78-ee35-d24f722e591d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7367"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CT = glob('/content/content/drive/MyDrive/CT_Data/CT_images/*')\n",
        "len(CT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nlq7CVflO71j",
        "outputId": "afae93eb-2c49-4890-808a-fa37a5b4f769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7367"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"image_path\": CT, \"mask_path\":mask_files})\n"
      ],
      "metadata": {
        "id": "ZnM6sPBsPES9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xval = train_test_split(df, test_size=0.15,random_state=101)\n",
        "Xtest, Xval = train_test_split(Xval, test_size=0.5)\n",
        "print(\"Train size is {}, valid size is {} & test size is {}\".format(len(Xtrain), len(Xval), len(Xtest)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCGWJCIdPZ-l",
        "outputId": "24dff151-617e-4187-d81c-635bcfa6b685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size is 6261, valid size is 553 & test size is 553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ids = list(Xtrain.image_path)\n",
        "train_mask = list(Xtrain.mask_path)\n",
        "\n",
        "val_ids = list(Xval.image_path)\n",
        "val_mask= list(Xval.mask_path)"
      ],
      "metadata": {
        "id": "c_nfcfIgQM53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tversky(ytrue, ypred):\n",
        "    ypredpos = K.flatten(ypred)\n",
        "    ytruepos = K.flatten(ytrue)\n",
        "    truepos = K.sum(ytruepos * ypredpos)\n",
        "    falseneg = K.sum(ytruepos * (1-ypredpos))\n",
        "    falsepos = K.sum((1-ytruepos)*ypredpos)\n",
        "    alpha = 0.7\n",
        "    smooth=100\n",
        "    return (truepos + smooth)/(truepos + alpha*falseneg + (1-alpha)*falsepos + smooth)\n",
        "\n",
        "def focaltversky(ytrue,ypred):\n",
        "    ypred = tf.cast(ypred, tf.float32)\n",
        "    ytrue = tf.cast(ytrue, tf.float32)\n",
        "    \n",
        "    pt_1 = tversky(ytrue, ypred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)\n",
        "\n",
        "def tversky_loss(ytrue, ypred):\n",
        "    return 1 - tversky(ytrue,ypred)"
      ],
      "metadata": {
        "id": "oiskjv6sPtp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "45pQ_nz67PoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(256,256,3)\n",
        "n_labels=3\n",
        "kernel=3\n",
        "pool_size=(2, 2)\n",
        "output_mode=\"softmax\"\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "    # encoder\n",
        "conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n",
        "conv_1 = BatchNormalization()(conv_1)\n",
        "conv_1 = Activation(\"relu\")(conv_1)\n",
        "conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n",
        "conv_2 = BatchNormalization()(conv_2)\n",
        "conv_2 = Activation(\"relu\")(conv_2)\n",
        "\n",
        "pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n",
        "\n",
        "conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n",
        "conv_3 = BatchNormalization()(conv_3)\n",
        "conv_3 = Activation(\"relu\")(conv_3)\n",
        "conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n",
        "conv_4 = BatchNormalization()(conv_4)\n",
        "conv_4 = Activation(\"relu\")(conv_4)\n",
        "\n",
        "pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n",
        "\n",
        "conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n",
        "conv_5 = BatchNormalization()(conv_5)\n",
        "conv_5 = Activation(\"relu\")(conv_5)\n",
        "conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n",
        "conv_6 = BatchNormalization()(conv_6)\n",
        "conv_6 = Activation(\"relu\")(conv_6)\n",
        "conv_7 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_6)\n",
        "conv_7 = BatchNormalization()(conv_7)\n",
        "conv_7 = Activation(\"relu\")(conv_7)\n",
        "\n",
        "pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)\n",
        "\n",
        "conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n",
        "conv_8 = BatchNormalization()(conv_8)\n",
        "conv_8 = Activation(\"relu\")(conv_8)\n",
        "conv_9 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_8)\n",
        "conv_9 = BatchNormalization()(conv_9)\n",
        "conv_9 = Activation(\"relu\")(conv_9)\n",
        "conv_10 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_9)\n",
        "conv_10 = BatchNormalization()(conv_10)\n",
        "conv_10 = Activation(\"relu\")(conv_10)\n",
        "\n",
        "pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)\n",
        "\n",
        "conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n",
        "conv_11 = BatchNormalization()(conv_11)\n",
        "conv_11 = Activation(\"relu\")(conv_11)\n",
        "conv_12 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_11)\n",
        "conv_12 = BatchNormalization()(conv_12)\n",
        "conv_12 = Activation(\"relu\")(conv_12)\n",
        "conv_13 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_12)\n",
        "conv_13 = BatchNormalization()(conv_13)\n",
        "conv_13 = Activation(\"relu\")(conv_13)\n",
        "\n",
        "pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)\n",
        "print(\"Build enceder done..\")\n",
        "\n",
        "# between encoder and decoder\n",
        "conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_5)\n",
        "conv_14 = BatchNormalization()(conv_14)\n",
        "conv_14 = Activation(\"relu\")(conv_14)\n",
        "conv_15 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_14)\n",
        "conv_15 = BatchNormalization()(conv_15)\n",
        "conv_15 = Activation(\"relu\")(conv_15)\n",
        "conv_16 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_15)\n",
        "conv_16 = BatchNormalization()(conv_16)\n",
        "conv_16 = Activation(\"relu\")(conv_16)\n",
        "\n",
        "# decoder\n",
        "unpool_1 = MaxUnpooling2D(pool_size)(conv_16,mask_5)\n",
        "concat_1 = Concatenate()([unpool_1, conv_13])\n",
        "\n",
        "conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(concat_1)\n",
        "conv_17 = BatchNormalization()(conv_17)\n",
        "conv_17 = Activation(\"relu\")(conv_17)\n",
        "conv_18 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_17)\n",
        "conv_18 = BatchNormalization()(conv_18)\n",
        "conv_18 = Activation(\"relu\")(conv_18)\n",
        "conv_19 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_18)\n",
        "conv_19 = BatchNormalization()(conv_19)\n",
        "conv_19 = Activation(\"relu\")(conv_19)\n",
        "\n",
        "unpool_2 = MaxUnpooling2D(pool_size)(conv_19, mask_4)\n",
        "concat_2 = Concatenate()([unpool_2, conv_10])\n",
        "\n",
        "conv_20 = Convolution2D(512, (kernel, kernel), padding=\"same\")(concat_2)\n",
        "conv_20 = BatchNormalization()(conv_20)\n",
        "conv_20 = Activation(\"relu\")(conv_20)\n",
        "conv_21 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_20)\n",
        "conv_21 = BatchNormalization()(conv_21)\n",
        "conv_21 = Activation(\"relu\")(conv_21)\n",
        "conv_22 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_21)\n",
        "conv_22 = BatchNormalization()(conv_22)\n",
        "conv_22 = Activation(\"relu\")(conv_22)\n",
        "\n",
        "unpool_3 = MaxUnpooling2D(pool_size)(conv_22, mask_3)\n",
        "concat_3 = Concatenate()([unpool_3, conv_7])\n",
        "\n",
        "conv_23 = Convolution2D(256, (kernel, kernel), padding=\"same\")(concat_3)\n",
        "conv_23 = BatchNormalization()(conv_23)\n",
        "conv_23 = Activation(\"relu\")(conv_23)\n",
        "conv_24 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_23)\n",
        "conv_24 = BatchNormalization()(conv_24)\n",
        "conv_24 = Activation(\"relu\")(conv_24)\n",
        "conv_25 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_24)\n",
        "conv_25 = BatchNormalization()(conv_25)\n",
        "conv_25 = Activation(\"relu\")(conv_25)\n",
        "\n",
        "unpool_4 = MaxUnpooling2D(pool_size)(conv_25, mask_2)\n",
        "concat_4 = Concatenate()([unpool_4, conv_4])\n",
        "\n",
        "conv_26 = Convolution2D(128, (kernel, kernel), padding=\"same\")(concat_4)\n",
        "conv_26 = BatchNormalization()(conv_26)\n",
        "conv_26 = Activation(\"relu\")(conv_26)\n",
        "conv_27 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_26)\n",
        "conv_27 = BatchNormalization()(conv_27)\n",
        "conv_27 = Activation(\"relu\")(conv_27)\n",
        "\n",
        "unpool_5 = MaxUnpooling2D(pool_size)(conv_27, mask_1)\n",
        "concat_5 = Concatenate()([unpool_5, conv_2])\n",
        "\n",
        "conv_28 = Convolution2D(64, (kernel, kernel), padding=\"same\")(concat_5)\n",
        "conv_28 = BatchNormalization()(conv_28)\n",
        "conv_28 = Activation(\"relu\")(conv_28)\n",
        "\n",
        "conv_29 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_28)\n",
        "conv_29 = BatchNormalization()(conv_29)\n",
        "conv_29 = Activation(output_mode)(conv_29)\n",
        "outputs = Reshape((256,256,3))(conv_29)\n",
        "\n",
        "print(\"Build decoder done..\")\n",
        "\n",
        "segunet = Model(inputs=inputs, outputs=outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "CPHwxvzY17bi",
        "outputId": "dc604f7f-789e-48b1-e8db-86ff719f81c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build enceder done..\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3fdd5e4e059b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0munpool_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxUnpooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mconcat_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munpool_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0mconv_17\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    526\u001b[0m             shape[axis] for shape in shape_set if shape[axis] is not None)\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dims\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 512, 512, 512), (None, 256, 256, 512)]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OwOGxiN0yfhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NW2QbXuc38w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def CreateSegUNet(input_shape=(256,256,3), n_labels=3, kernel=3, pool_size=(2, 2), output_mode=\"softmax\"):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # encoder\n",
        "    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n",
        "    conv_1 = BatchNormalization()(conv_1)\n",
        "    conv_1 = Activation(\"relu\")(conv_1)\n",
        "    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n",
        "    conv_2 = BatchNormalization()(conv_2)\n",
        "    conv_2 = Activation(\"relu\")(conv_2)\n",
        "\n",
        "    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n",
        "\n",
        "    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n",
        "    conv_3 = BatchNormalization()(conv_3)\n",
        "    conv_3 = Activation(\"relu\")(conv_3)\n",
        "    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n",
        "    conv_4 = BatchNormalization()(conv_4)\n",
        "    conv_4 = Activation(\"relu\")(conv_4)\n",
        "\n",
        "    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n",
        "\n",
        "    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n",
        "    conv_5 = BatchNormalization()(conv_5)\n",
        "    conv_5 = Activation(\"relu\")(conv_5)\n",
        "    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n",
        "    conv_6 = BatchNormalization()(conv_6)\n",
        "    conv_6 = Activation(\"relu\")(conv_6)\n",
        "    conv_7 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_6)\n",
        "    conv_7 = BatchNormalization()(conv_7)\n",
        "    conv_7 = Activation(\"relu\")(conv_7)\n",
        "\n",
        "    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)\n",
        "\n",
        "    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n",
        "    conv_8 = BatchNormalization()(conv_8)\n",
        "    conv_8 = Activation(\"relu\")(conv_8)\n",
        "    conv_9 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_8)\n",
        "    conv_9 = BatchNormalization()(conv_9)\n",
        "    conv_9 = Activation(\"relu\")(conv_9)\n",
        "    conv_10 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_9)\n",
        "    conv_10 = BatchNormalization()(conv_10)\n",
        "    conv_10 = Activation(\"relu\")(conv_10)\n",
        "\n",
        "    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)\n",
        "\n",
        "    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n",
        "    conv_11 = BatchNormalization()(conv_11)\n",
        "    conv_11 = Activation(\"relu\")(conv_11)\n",
        "    conv_12 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_11)\n",
        "    conv_12 = BatchNormalization()(conv_12)\n",
        "    conv_12 = Activation(\"relu\")(conv_12)\n",
        "    conv_13 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_12)\n",
        "    conv_13 = BatchNormalization()(conv_13)\n",
        "    conv_13 = Activation(\"relu\")(conv_13)\n",
        "\n",
        "    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)\n",
        "    print(\"Build enceder done..\")\n",
        "\n",
        "    # between encoder and decoder\n",
        "    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_5)\n",
        "    conv_14 = BatchNormalization()(conv_14)\n",
        "    conv_14 = Activation(\"relu\")(conv_14)\n",
        "    conv_15 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_14)\n",
        "    conv_15 = BatchNormalization()(conv_15)\n",
        "    conv_15 = Activation(\"relu\")(conv_15)\n",
        "    conv_16 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_15)\n",
        "    conv_16 = BatchNormalization()(conv_16)\n",
        "    conv_16 = Activation(\"relu\")(conv_16)\n",
        "\n",
        "    # decoder\n",
        "    unpool_1 = MaxUnpooling2D(pool_size)(conv_16, mask_5)\n",
        "    concat_1 = Concatenate()([unpool_1, conv_13])\n",
        "\n",
        "    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(concat_1)\n",
        "    conv_17 = BatchNormalization()(conv_17)\n",
        "    conv_17 = Activation(\"relu\")(conv_17)\n",
        "    conv_18 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_17)\n",
        "    conv_18 = BatchNormalization()(conv_18)\n",
        "    conv_18 = Activation(\"relu\")(conv_18)\n",
        "    conv_19 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_18)\n",
        "    conv_19 = BatchNormalization()(conv_19)\n",
        "    conv_19 = Activation(\"relu\")(conv_19)\n",
        "\n",
        "    unpool_2 = MaxUnpooling2D(pool_size)(conv_19, mask_4)\n",
        "    concat_2 = Concatenate()([unpool_2, conv_10])\n",
        "\n",
        "    conv_20 = Convolution2D(512, (kernel, kernel), padding=\"same\")(concat_2)\n",
        "    conv_20 = BatchNormalization()(conv_20)\n",
        "    conv_20 = Activation(\"relu\")(conv_20)\n",
        "    conv_21 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_20)\n",
        "    conv_21 = BatchNormalization()(conv_21)\n",
        "    conv_21 = Activation(\"relu\")(conv_21)\n",
        "    conv_22 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_21)\n",
        "    conv_22 = BatchNormalization()(conv_22)\n",
        "    conv_22 = Activation(\"relu\")(conv_22)\n",
        "\n",
        "    unpool_3 = MaxUnpooling2D(pool_size)(conv_22, mask_3)\n",
        "    concat_3 = Concatenate()([unpool_3, conv_7])\n",
        "\n",
        "    conv_23 = Convolution2D(256, (kernel, kernel), padding=\"same\")(concat_3)\n",
        "    conv_23 = BatchNormalization()(conv_23)\n",
        "    conv_23 = Activation(\"relu\")(conv_23)\n",
        "    conv_24 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_23)\n",
        "    conv_24 = BatchNormalization()(conv_24)\n",
        "    conv_24 = Activation(\"relu\")(conv_24)\n",
        "    conv_25 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_24)\n",
        "    conv_25 = BatchNormalization()(conv_25)\n",
        "    conv_25 = Activation(\"relu\")(conv_25)\n",
        "\n",
        "    unpool_4 = MaxUnpooling2D(pool_size)(conv_25, mask_2)\n",
        "    concat_4 = Concatenate()([unpool_4, conv_4])\n",
        "\n",
        "    conv_26 = Convolution2D(128, (kernel, kernel), padding=\"same\")(concat_4)\n",
        "    conv_26 = BatchNormalization()(conv_26)\n",
        "    conv_26 = Activation(\"relu\")(conv_26)\n",
        "    conv_27 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_26)\n",
        "    conv_27 = BatchNormalization()(conv_27)\n",
        "    conv_27 = Activation(\"relu\")(conv_27)\n",
        "\n",
        "    unpool_5 = MaxUnpooling2D(pool_size)(conv_27, mask_1)\n",
        "    concat_5 = Concatenate()([unpool_5, conv_2])\n",
        "\n",
        "    conv_28 = Convolution2D(64, (kernel, kernel), padding=\"same\")(concat_5)\n",
        "    conv_28 = BatchNormalization()(conv_28)\n",
        "    conv_28 = Activation(\"relu\")(conv_28)\n",
        "\n",
        "    conv_29 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_28)\n",
        "    conv_29 = BatchNormalization()(conv_29)\n",
        "    conv_29 = Activation(output_mode)(conv_29)\n",
        "    outputs = Reshape((256,256,3))(conv_29)\n",
        "\n",
        "    print(\"Build decoder done..\")\n",
        "\n",
        "    segunet = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return segunet"
      ],
      "metadata": {
        "id": "30cVXDmaZCm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputshape = (256,256,3)\n",
        "Res_Unet_model=CreateSegUNet(inputshape)"
      ],
      "metadata": {
        "id": "s6u3VG5V4NW6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "347b5146-f38e-4c3d-99fe-92bc14a886dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build enceder done..\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-292bb928351a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minputshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mRes_Unet_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCreateSegUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-cac591595992>\u001b[0m in \u001b[0;36mCreateSegUNet\u001b[0;34m(input_shape, n_labels, kernel, pool_size, output_mode)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0munpool_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxUnpooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mconcat_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munpool_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling layer \"max_unpooling2d_2\" (type MaxUnpooling2D).\n\nin user code:\n\n    File \"<ipython-input-3-4a76f128fd44>\", line 43, in call  *\n        with K.tf.variable_scope(self.name):\n\n    AttributeError: module 'tensorflow.compat.v2' has no attribute 'variable_scope'\n\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 8, 8, 512), dtype=float32)\n  • output_shape=tf.Tensor(shape=(None, 8, 8, 512), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Res_Unet_model.summary()"
      ],
      "metadata": {
        "id": "ZgecCgXTZ9bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def __init__(self, ids , mask, image_dir = './', batch_size = 16, img_h = 256, img_w = 256, shuffle = True):\n",
        "    self.ids = ids\n",
        "    self.mask = mask\n",
        "    self.image_dir = image_dir\n",
        "    self.batch_size = batch_size\n",
        "    self.img_h = img_h\n",
        "    self.img_w = img_w\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.ids)) / self.batch_size)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    indexes = self.indexes[index* self.batch_size : (index+1) * self.batch_size]\n",
        "    list_ids = [self.ids[i] for i in indexes]\n",
        "    list_mask = [self.mask[i] for i in indexes]\n",
        "    X, y = self.__data_generation(list_ids, list_mask)\n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):    \n",
        "    self.indexes = np.arange(len(self.ids))\n",
        "\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __data_generation(self, list_ids, list_mask):\n",
        "\n",
        "    X = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n",
        "    y = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n",
        "\n",
        "    for i in range(len(list_ids)):\n",
        "      img_path = str(list_ids[i])\n",
        "      mask_path = str(list_mask[i])\n",
        "      img = io.imread(img_path)\n",
        "      mask = io.imread(mask_path)\n",
        "      img = cv2.resize(img,(self.img_h,self.img_w))\n",
        "      img = np.array(img, dtype = np.float64)\n",
        "      mask = cv2.resize(mask,(self.img_h,self.img_w))\n",
        "      mask = np.array(mask, dtype = np.float64)\n",
        "      img -= img.mean()\n",
        "      img /= img.std()\n",
        "      mask -= mask.mean()\n",
        "      mask /= mask.std()\n",
        "      X[i,] = img\n",
        "      y[i,] = mask\n",
        "    y = (y > 0).astype(int)\n",
        "    return X, y\n",
        "\n",
        "train_data = DataGenerator(train_ids, train_mask)\n",
        "val_data = DataGenerator(val_ids, val_mask)"
      ],
      "metadata": {
        "id": "3VJ_bEqZ9oca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystopping = EarlyStopping(monitor='val_loss',\n",
        "                              mode='min', \n",
        "                              verbose=1, \n",
        "                              patience=20\n",
        "                             )\n",
        "checkpointer = ModelCheckpoint(filepath=\"/content/drive/MyDrive/SegUnet/SegUnet.h5\", \n",
        "                               verbose=1, \n",
        "                               save_best_only=True\n",
        "                              )\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              mode='min',\n",
        "                              verbose=1,\n",
        "                              patience=10,\n",
        "                              min_delta=0.0001,\n",
        "                              factor=0.2\n",
        "                             )\n",
        "filename='/content/drive/MyDrive/SegUnet/history.csv'\n",
        "history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)"
      ],
      "metadata": {
        "id": "QXaO0qZ6QvyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth=100\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_truef=K.flatten(y_true)\n",
        "    y_predf=K.flatten(y_pred)\n",
        "    And=K.sum(y_truef* y_predf)\n",
        "    return ((2* And + smooth) / (K.sum(y_truef) + K.sum(y_predf) + smooth))"
      ],
      "metadata": {
        "id": "8xa2mfWwHjPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "QX2nBb9LHkr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iou(y_true, y_pred, smooth = 100):\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    sum_ = K.sum(y_true + y_pred)\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return jac"
      ],
      "metadata": {
        "id": "p21dnLVuHpNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam(lr = 0.01, epsilon = 0.1)\n",
        "Res_Unet_model.compile(optimizer = adam, \n",
        "                  loss = dice_coef_loss, \n",
        "                  metrics = [dice_coef,iou,Recall(),Precision()]\n",
        "                 )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "lQlKuaVqQaZb",
        "outputId": "aa633caf-562e-45a5-8eac-115419592f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-704655a8e5fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0madam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m Res_Unet_model.compile(optimizer = adam, \n\u001b[0m\u001b[1;32m      3\u001b[0m                   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_coef_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdice_coef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miou\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPrecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Res_Unet_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Res_Unet_model.load_weights(\"/content/drive/MyDrive/CT_res_att_unet/CT_res_att_unet.h5\")"
      ],
      "metadata": {
        "id": "l8hoDyB8bajD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Res_Unet_model.fit(train_data, \n",
        "                  epochs = 100,\n",
        "                  validation_data = val_data,\n",
        "                  callbacks = [checkpointer, earlystopping, reduce_lr,history_logger]\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0sJF49FRn_5",
        "outputId": "9b23cb95-ce12-48be-ef93-d675dfcc39bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        }
      ]
    }
  ]
}