{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 6_layers_ResUnetAttentionipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QawvgeYEYaI8"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input,Conv2D, Conv3D, MaxPooling3D,UpSampling2D, UpSampling3D,MaxPooling2D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate,Add\n",
        "import keras as Ks\n",
        "from keras.layers import Input\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from skimage import io\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.metrics import Precision, Recall, MeanIoU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGWPD-JSQ9pD",
        "outputId": "e64d657b-27b6-48c1-fb11-0e79a693d94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --no-cache-dir gdown --pre\n",
        "!gdown --id 1-2HGO0znF0JAsgZ_et5Cr_owKVxr_bKZ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioCsI4LEOFPK",
        "outputId": "02968264-95c0-4918-ee56-19a28d851184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14774 sha256=4f3b9c36c617360ed27035eb63a46e41c32d6a24395725182e022dff128d3a36\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0lb0gbq_/wheels/fb/c3/0e/c4d8ff8bfcb0461afff199471449f642179b74968c15b7a69c\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.2.2\n",
            "    Uninstalling gdown-4.2.2:\n",
            "      Successfully uninstalled gdown-4.2.2\n",
            "Successfully installed gdown-4.4.0\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-2HGO0znF0JAsgZ_et5Cr_owKVxr_bKZ\n",
            "To: /content/CT_Data.zip\n",
            "100% 624M/624M [00:36<00:00, 17.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1-2HGO0znF0JAsgZ_et5Cr_owKVxr_bKZ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km7lnals4d1-",
        "outputId": "3445d077-eedb-4d42-ff80-0ac53c809b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-2HGO0znF0JAsgZ_et5Cr_owKVxr_bKZ\n",
            "To: /content/CT_Data.zip\n",
            "100% 624M/624M [00:03<00:00, 179MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "file_name=\"/content/CT_Data.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as ziip:\n",
        "  ziip.extractall()\n",
        "  print('woow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nernz1QdOWP4",
        "outputId": "64315dcd-cd8c-4d4b-c759-cdc3ee579c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "woow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_files = glob('/content/content/drive/MyDrive/CT_Data/Masks/*')\n",
        "len(mask_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QV-NzPMOzO6",
        "outputId": "93b009cd-bec6-419b-955f-c370fa8b71b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7367"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CT = glob('/content/content/drive/MyDrive/CT_Data/CT_images/*')\n",
        "len(CT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nlq7CVflO71j",
        "outputId": "e64081d1-21f1-4f95-9dd0-0ee4cbe95fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7367"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"image_path\": CT, \"mask_path\":mask_files})\n"
      ],
      "metadata": {
        "id": "ZnM6sPBsPES9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xval = train_test_split(df, test_size=0.15)\n",
        "Xtest, Xval = train_test_split(Xval, test_size=0.5)\n",
        "print(\"Train size is {}, valid size is {} & test size is {}\".format(len(Xtrain), len(Xval), len(Xtest)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCGWJCIdPZ-l",
        "outputId": "0dc3cc37-ac38-4e4c-b499-3c0b9b653b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size is 6261, valid size is 553 & test size is 553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ids = list(Xtrain.image_path)\n",
        "train_mask = list(Xtrain.mask_path)\n",
        "\n",
        "val_ids = list(Xval.image_path)\n",
        "val_mask= list(Xval.mask_path)"
      ],
      "metadata": {
        "id": "c_nfcfIgQM53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tversky(ytrue, ypred):\n",
        "    ypredpos = K.flatten(ypred)\n",
        "    ytruepos = K.flatten(ytrue)\n",
        "    truepos = K.sum(ytruepos * ypredpos)\n",
        "    falseneg = K.sum(ytruepos * (1-ypredpos))\n",
        "    falsepos = K.sum((1-ytruepos)*ypredpos)\n",
        "    alpha = 0.7\n",
        "    smooth=100\n",
        "    return (truepos + smooth)/(truepos + alpha*falseneg + (1-alpha)*falsepos + smooth)\n",
        "\n",
        "def focaltversky(ytrue,ypred):\n",
        "    ypred = tf.cast(ypred, tf.float32)\n",
        "    ytrue = tf.cast(ytrue, tf.float32)\n",
        "    \n",
        "    pt_1 = tversky(ytrue, ypred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)\n",
        "\n",
        "def tversky_loss(ytrue, ypred):\n",
        "    return 1 - tversky(ytrue,ypred)"
      ],
      "metadata": {
        "id": "oiskjv6sPtp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth=100\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_truef=K.flatten(y_true)\n",
        "    y_predf=K.flatten(y_pred)\n",
        "    And=K.sum(y_truef* y_predf)\n",
        "    return((2* And + smooth) / (K.sum(y_truef) + K.sum(y_predf) + smooth))\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "V-KvuanMGoXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resblock(X, f):\n",
        " \n",
        "    Xcopy = X  \n",
        "    \n",
        "    # main path\n",
        "    X = Conv2D(f, kernel_size=(1,1), kernel_initializer='he_normal')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(f, kernel_size=(3,3), padding='same', kernel_initializer='he_normal')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    \n",
        "    # shortcut path\n",
        "    Xcopy = Conv2D(f, kernel_size=(1,1), kernel_initializer='he_normal')(Xcopy)\n",
        "    Xcopy = BatchNormalization()(Xcopy)\n",
        "    \n",
        "    # Adding the output from main path and short path together\n",
        "    X = Add()([X, Xcopy])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X\n",
        "\n",
        "def attention_block(L,X ,numfilters):\n",
        "    ## Getting shapes if the layers\n",
        "    shape_X=X.shape\n",
        "    shape_L=L.shape\n",
        "\n",
        "    ## getting x to the same shape as L\n",
        "    theta_x=Conv2D(numfilters,(1,1),strides=(1,1),padding=\"same\")(X)\n",
        "    shape_X_theta=theta_x.shape\n",
        "    phy_L=Conv2D(numfilters,(1,1),strides=(2,2),padding=\"same\")(L)\n",
        "    shape_L_phy=phy_L.shape\n",
        "    ##Adding the 2 layers together\n",
        "    XL= Ks.layers.add([theta_x,phy_L])\n",
        "    activate_XL=Ks.layers.Activation('relu')(XL)\n",
        "    conv=Conv2D(1,(1,1),padding='same')(activate_XL)\n",
        "    \n",
        "    act_sigmoid=Ks.layers.Activation('sigmoid')(conv)\n",
        "    shape_sig=act_sigmoid.shape\n",
        "    ##upsampling \n",
        "    upsampled=Ks.layers.UpSampling2D(size=(shape_L[1]//shape_sig[1],shape_L[2]//shape_sig[2]))(act_sigmoid)\n",
        "\n",
        "    #output\n",
        "    y=Ks.layers.multiply([upsampled,L])\n",
        "    out=Conv2D(shape_L[3],(1,1),padding='same')(y)\n",
        "    return out\n",
        "\n",
        "\n",
        "def upsample_concat_with_attention_block(x, skip,num_filters):\n",
        "    '''\n",
        "    funtion for upsampling image\n",
        "    '''\n",
        "    m=attention_block(skip,x,num_filters)\n",
        "    S= UpSampling2D((2,2))(x)\n",
        "    # X= Concatenate()([S,skip])\n",
        "    \n",
        "    merge = Concatenate()([m,S])\n",
        "    \n",
        "    return merge"
      ],
      "metadata": {
        "id": "jBhfaQA8Y2ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Res_Unet_with_att_model(inputshape=(256,256,3),filter_num=8,pool_size=(2, 2),n_classes=3):\n",
        "  Xinput = Input(inputshape)\n",
        "\n",
        "  conv_1 = Conv2D(2*filter_num, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(Xinput)\n",
        "  conv_1 = BatchNormalization()(conv_1)\n",
        "  conv_1 = Conv2D(2*filter_num, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv_1)\n",
        "  conv_1 = BatchNormalization()(conv_1)\n",
        "  pool_1 = MaxPool2D(pool_size)(conv_1)\n",
        "\n",
        "\n",
        "  conv_2 = resblock(pool_1, 4*filter_num)\n",
        "  pool_2 = MaxPooling2D(pool_size)(conv_2)\n",
        "\n",
        "\n",
        "  conv_3 = resblock(pool_2, 8*filter_num)\n",
        "  pool_3 = MaxPooling2D(pool_size)(conv_3)\n",
        "\n",
        "\n",
        "  conv_4 = resblock(pool_3, 16*filter_num)\n",
        "  pool_4 = MaxPooling2D(pool_size)(conv_4)\n",
        "\n",
        "\n",
        "  conv_5 = resblock(pool_4, 32*filter_num)\n",
        "  pool_5 = MaxPooling2D(pool_size)(conv_5)\n",
        "\n",
        "  conv_6 = resblock(pool_5, 64*filter_num)\n",
        "\n",
        "\n",
        "  up_1 = upsample_concat_with_attention_block(conv_6, conv_5,32*filter_num)\n",
        "  up_1 = resblock(up_1, 32*filter_num)\n",
        "\n",
        "\n",
        "  up_2 = upsample_concat_with_attention_block(up_1, conv_4,16*filter_num)\n",
        "  up_2 = resblock(up_2, 16*filter_num)\n",
        "\n",
        "\n",
        "  up_3 = upsample_concat_with_attention_block(up_2, conv_3,8*filter_num)\n",
        "  up_3 = resblock(up_3, 8*filter_num)\n",
        "\n",
        "\n",
        "  up_4 = upsample_concat_with_attention_block(up_3, conv_2,4*filter_num)\n",
        "  up_4 = resblock(up_4, 4*filter_num)\n",
        "\n",
        "\n",
        "  up_5 = upsample_concat_with_attention_block(up_4, conv_1,2*filter_num)\n",
        "  up_5 = resblock(up_5, 2*filter_num)\n",
        "\n",
        "  out = Conv2D(n_classes, (1,1), kernel_initializer='he_normal', padding='same', activation='sigmoid')(up_5)\n",
        "  Res_Unet_with_att_model=Model(Xinput, out)\n",
        "  return Res_Unet_with_att_model"
      ],
      "metadata": {
        "id": "30cVXDmaZCm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputshape = (256,256,3)\n",
        "Res_Unet_model=Res_Unet_with_att_model(inputshape)"
      ],
      "metadata": {
        "id": "s6u3VG5V4NW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Res_Unet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgecCgXTZ9bb",
        "outputId": "c9f0922b-3455-48e7-926c-bbee88a56b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 16  448         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 256, 256, 16  64         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 16  2320        ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 256, 256, 16  64         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 16  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 32  544         ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 32  128        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 128, 128, 32  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 32  9248        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 32  544         ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 128, 32  128        ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128, 128, 32  128        ['conv2d_4[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 128, 128, 32  0           ['batch_normalization_3[0][0]',  \n",
            "                                )                                 'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 128, 128, 32  0           ['add[0][0]']                    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)  0           ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 64)   2112        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 64, 64, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 64, 64, 64)   36928       ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 64, 64, 64)   2112        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 64, 64, 64)   0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 64, 64, 64)   0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)  0           ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 128)  8320        ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 32, 32, 128)  0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 128)  147584      ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 128)  8320        ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 128)  512        ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 128)  0           ['batch_normalization_9[0][0]',  \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 128)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 256)  33024       ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 256)  590080      ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 256)  33024       ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 256)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 256)   0           ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 8, 8, 512)    131584      ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 8, 8, 512)    0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 8, 8, 512)    2359808     ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 8, 8, 512)    131584      ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_15[0][0]', \n",
            "                                                                  'batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 8, 8, 512)    0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 8, 8, 256)    131328      ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 8, 8, 256)    65792       ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 8, 8, 256)    0           ['conv2d_17[0][0]',              \n",
            "                                                                  'conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 8, 8, 256)    0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 8, 8, 1)      257         ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 8, 8, 1)      0           ['conv2d_19[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 16, 16, 1)    0           ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 16, 16, 256)  0           ['up_sampling2d[0][0]',          \n",
            "                                                                  'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 256)  65792       ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 512)  0          ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 16, 768)  0           ['conv2d_20[0][0]',              \n",
            "                                                                  'up_sampling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 256)  196864      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 256)  590080      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 256)  196864      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 16, 16, 256)  0           ['batch_normalization_18[0][0]', \n",
            "                                                                  'batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 256)  0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 128)  32896       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 128)  16512       ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 16, 16, 128)  0           ['conv2d_24[0][0]',              \n",
            "                                                                  'conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 128)  0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 16, 16, 1)    129         ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 1)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 1)   0           ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 32, 32, 128)  0           ['up_sampling2d_2[0][0]',        \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 32, 32, 128)  16512       ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 32, 32, 256)  0          ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 32, 32, 384)  0           ['conv2d_27[0][0]',              \n",
            "                                                                  'up_sampling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 32, 32, 128)  49280       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 32, 32, 128)  512        ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 32, 32, 128)  147584      ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 32, 32, 128)  49280       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 32, 32, 128)  512        ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 32, 32, 128)  512        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 32, 32, 128)  0           ['batch_normalization_21[0][0]', \n",
            "                                                                  'batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 32, 32, 128)  0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 32, 32, 64)   8256        ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 32, 32, 64)   4160        ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 32, 32, 64)   0           ['conv2d_31[0][0]',              \n",
            "                                                                  'conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 32, 32, 64)   0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 32, 32, 1)    65          ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 32, 32, 1)    0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 1)   0           ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 64, 64, 64)   0           ['up_sampling2d_4[0][0]',        \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 64, 64, 64)   4160        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 128)  0          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 64, 64, 192)  0           ['conv2d_34[0][0]',              \n",
            "                                                                  'up_sampling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 64, 64, 64)   12352       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 64, 64, 64)  256         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 64, 64, 64)   12352       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 64, 64, 64)  256         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 64, 64, 64)  256         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 64, 64, 64)   0           ['batch_normalization_24[0][0]', \n",
            "                                                                  'batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 64, 64, 64)   0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 64, 64, 32)   2080        ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 64, 64, 32)   1056        ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 64, 64, 32)   0           ['conv2d_38[0][0]',              \n",
            "                                                                  'conv2d_39[0][0]']              \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 64, 64, 32)   0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 64, 64, 1)    33          ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 64, 64, 1)    0           ['conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 1)  0          ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 128, 128, 32  0           ['up_sampling2d_6[0][0]',        \n",
            "                                )                                 'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 128, 128, 32  1056        ['multiply_3[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 64  0          ['activation_21[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 128, 128, 96  0           ['conv2d_41[0][0]',              \n",
            "                                )                                 'up_sampling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 128, 128, 32  3104        ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 128, 128, 32  128        ['conv2d_42[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_26[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 128, 128, 32  9248        ['activation_24[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 128, 128, 32  3104        ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 128, 128, 32  128        ['conv2d_43[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 128, 128, 32  128        ['conv2d_44[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 128, 128, 32  0           ['batch_normalization_27[0][0]', \n",
            "                                )                                 'batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 128, 128, 32  0           ['add_12[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 128, 128, 16  528         ['activation_25[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 128, 128, 16  272         ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 128, 128, 16  0           ['conv2d_45[0][0]',              \n",
            "                                )                                 'conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 128, 128, 16  0           ['add_13[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 128, 128, 1)  17          ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 128, 128, 1)  0           ['conv2d_47[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_8 (UpSampling2D)  (None, 256, 256, 1)  0          ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 256, 256, 16  0           ['up_sampling2d_8[0][0]',        \n",
            "                                )                                 'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 256, 256, 16  272         ['multiply_4[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_9 (UpSampling2D)  (None, 256, 256, 32  0          ['activation_25[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 256, 256, 48  0           ['conv2d_48[0][0]',              \n",
            "                                )                                 'up_sampling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 256, 256, 16  784         ['concatenate_4[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 256, 256, 16  64         ['conv2d_49[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_29[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 256, 256, 16  2320        ['activation_28[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 256, 256, 16  784         ['concatenate_4[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 256, 256, 16  64         ['conv2d_50[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 256, 256, 16  64         ['conv2d_51[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 256, 256, 16  0           ['batch_normalization_30[0][0]', \n",
            "                                )                                 'batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 256, 256, 16  0           ['add_14[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 256, 256, 3)  51          ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,177,720\n",
            "Trainable params: 5,168,728\n",
            "Non-trainable params: 8,992\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def __init__(self, ids , mask, image_dir = './', batch_size = 16, img_h = 256, img_w = 256, shuffle = True):\n",
        "    self.ids = ids\n",
        "    self.mask = mask\n",
        "    self.image_dir = image_dir\n",
        "    self.batch_size = batch_size\n",
        "    self.img_h = img_h\n",
        "    self.img_w = img_w\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.ids)) / self.batch_size)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    indexes = self.indexes[index* self.batch_size : (index+1) * self.batch_size]\n",
        "    list_ids = [self.ids[i] for i in indexes]\n",
        "    list_mask = [self.mask[i] for i in indexes]\n",
        "    X, y = self.__data_generation(list_ids, list_mask)\n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):    \n",
        "    self.indexes = np.arange(len(self.ids))\n",
        "\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __data_generation(self, list_ids, list_mask):\n",
        "\n",
        "    X = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n",
        "    y = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n",
        "\n",
        "    for i in range(len(list_ids)):\n",
        "      img_path = str(list_ids[i])\n",
        "      mask_path = str(list_mask[i])\n",
        "      img = io.imread(img_path)\n",
        "      mask = io.imread(mask_path)\n",
        "      img = cv2.resize(img,(self.img_h,self.img_w))\n",
        "      img = np.array(img, dtype = np.float64)\n",
        "      mask = cv2.resize(mask,(self.img_h,self.img_w))\n",
        "      mask = np.array(mask, dtype = np.float64)\n",
        "      img -= img.mean()\n",
        "      img /= img.std()\n",
        "      mask -= mask.mean()\n",
        "      mask /= mask.std()\n",
        "      X[i,] = img\n",
        "      y[i,] = mask\n",
        "    y = (y > 0).astype(int)\n",
        "    return X, y\n",
        "\n",
        "train_data = DataGenerator(train_ids, train_mask)\n",
        "val_data = DataGenerator(val_ids, val_mask)"
      ],
      "metadata": {
        "id": "3VJ_bEqZ9oca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystopping = EarlyStopping(monitor='val_loss',\n",
        "                              mode='min', \n",
        "                              verbose=1, \n",
        "                              patience=20\n",
        "                             )\n",
        "checkpointer = ModelCheckpoint(filepath=\"/content/drive/MyDrive/CT_res_att_unet_2/CT_res_att_unet.h5\", \n",
        "                               verbose=1, \n",
        "                               save_best_only=True\n",
        "                              )\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              mode='min',\n",
        "                              verbose=1,\n",
        "                              patience=10,\n",
        "                              min_delta=0.0001,\n",
        "                              factor=0.2\n",
        "                             )\n",
        "filename='/content/drive/MyDrive/CT_res_att_unet_2/history.csv'\n",
        "history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)"
      ],
      "metadata": {
        "id": "QXaO0qZ6QvyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam(lr = 0.001, epsilon = 0.1)\n",
        "Res_Unet_model.compile(optimizer = adam, \n",
        "                  loss = focaltversky, \n",
        "                  metrics = [Recall(), Precision(),dice_coef,tversky, MeanIoU(num_classes=6)]\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQlKuaVqQaZb",
        "outputId": "b44b8dfa-1bc9-40b6-f6c0-aa7a37a3e558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Res_Unet_model.load_weights(\"/content/drive/MyDrive/CT_res_att_unet/CT_res_att_unet.h5\")"
      ],
      "metadata": {
        "id": "l8hoDyB8bajD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Res_Unet_model.fit(train_data, \n",
        "                  epochs = 200,\n",
        "                  initial_epoch=57,\n",
        "                  validation_data = val_data,\n",
        "                  callbacks = [checkpointer, earlystopping, reduce_lr,history_logger]\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0sJF49FRn_5",
        "outputId": "dd7e98ba-d90a-4988-f92d-506294156c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2577 - recall_1: 0.7935 - precision_1: 0.8925 - dice_coef: 0.8417 - tversky: 0.8340 - mean_io_u_1: 0.8373\n",
            "Epoch 58: val_loss improved from inf to 0.25745, saving model to /content/drive/MyDrive/CT_res_att_unet_2/CT_res_att_unet.h5\n",
            "391/391 [==============================] - 232s 539ms/step - loss: 0.2577 - recall_1: 0.7935 - precision_1: 0.8925 - dice_coef: 0.8417 - tversky: 0.8340 - mean_io_u_1: 0.8373 - val_loss: 0.2575 - val_recall_1: 0.7906 - val_precision_1: 0.8929 - val_dice_coef: 0.8467 - val_tversky: 0.8350 - val_mean_io_u_1: 0.8359 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2495 - recall_1: 0.7942 - precision_1: 0.8930 - dice_coef: 0.8483 - tversky: 0.8399 - mean_io_u_1: 0.8376\n",
            "Epoch 59: val_loss did not improve from 0.25745\n",
            "391/391 [==============================] - 207s 530ms/step - loss: 0.2495 - recall_1: 0.7942 - precision_1: 0.8930 - dice_coef: 0.8483 - tversky: 0.8399 - mean_io_u_1: 0.8376 - val_loss: 0.2615 - val_recall_1: 0.7914 - val_precision_1: 0.8919 - val_dice_coef: 0.8433 - val_tversky: 0.8317 - val_mean_io_u_1: 0.8371 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2503 - recall_1: 0.7944 - precision_1: 0.8942 - dice_coef: 0.8487 - tversky: 0.8400 - mean_io_u_1: 0.8374\n",
            "Epoch 60: val_loss improved from 0.25745 to 0.24986, saving model to /content/drive/MyDrive/CT_res_att_unet_2/CT_res_att_unet.h5\n",
            "391/391 [==============================] - 211s 540ms/step - loss: 0.2503 - recall_1: 0.7944 - precision_1: 0.8942 - dice_coef: 0.8487 - tversky: 0.8400 - mean_io_u_1: 0.8374 - val_loss: 0.2499 - val_recall_1: 0.7904 - val_precision_1: 0.8952 - val_dice_coef: 0.8481 - val_tversky: 0.8404 - val_mean_io_u_1: 0.8361 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2508 - recall_1: 0.7946 - precision_1: 0.8952 - dice_coef: 0.8486 - tversky: 0.8393 - mean_io_u_1: 0.8377\n",
            "Epoch 61: val_loss did not improve from 0.24986\n",
            "391/391 [==============================] - 207s 530ms/step - loss: 0.2508 - recall_1: 0.7946 - precision_1: 0.8952 - dice_coef: 0.8486 - tversky: 0.8393 - mean_io_u_1: 0.8377 - val_loss: 0.2513 - val_recall_1: 0.7916 - val_precision_1: 0.8939 - val_dice_coef: 0.8509 - val_tversky: 0.8392 - val_mean_io_u_1: 0.8378 - lr: 0.0010\n",
            "Epoch 62/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2515 - recall_1: 0.7951 - precision_1: 0.8950 - dice_coef: 0.8477 - tversky: 0.8389 - mean_io_u_1: 0.8383\n",
            "Epoch 62: val_loss did not improve from 0.24986\n",
            "391/391 [==============================] - 208s 531ms/step - loss: 0.2515 - recall_1: 0.7951 - precision_1: 0.8950 - dice_coef: 0.8477 - tversky: 0.8389 - mean_io_u_1: 0.8383 - val_loss: 0.2660 - val_recall_1: 0.7906 - val_precision_1: 0.8943 - val_dice_coef: 0.8376 - val_tversky: 0.8274 - val_mean_io_u_1: 0.8359 - lr: 0.0010\n",
            "Epoch 63/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2485 - recall_1: 0.7953 - precision_1: 0.8959 - dice_coef: 0.8497 - tversky: 0.8411 - mean_io_u_1: 0.8384\n",
            "Epoch 63: val_loss did not improve from 0.24986\n",
            "391/391 [==============================] - 207s 530ms/step - loss: 0.2485 - recall_1: 0.7953 - precision_1: 0.8959 - dice_coef: 0.8497 - tversky: 0.8411 - mean_io_u_1: 0.8384 - val_loss: 0.2670 - val_recall_1: 0.7919 - val_precision_1: 0.8876 - val_dice_coef: 0.8380 - val_tversky: 0.8275 - val_mean_io_u_1: 0.8388 - lr: 0.0010\n",
            "Epoch 64/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2489 - recall_1: 0.7958 - precision_1: 0.8966 - dice_coef: 0.8505 - tversky: 0.8413 - mean_io_u_1: 0.8386\n",
            "Epoch 64: val_loss did not improve from 0.24986\n",
            "391/391 [==============================] - 209s 534ms/step - loss: 0.2489 - recall_1: 0.7958 - precision_1: 0.8966 - dice_coef: 0.8505 - tversky: 0.8413 - mean_io_u_1: 0.8386 - val_loss: 0.2570 - val_recall_1: 0.7903 - val_precision_1: 0.8914 - val_dice_coef: 0.8453 - val_tversky: 0.8344 - val_mean_io_u_1: 0.8372 - lr: 0.0010\n",
            "Epoch 65/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2479 - recall_1: 0.7960 - precision_1: 0.8974 - dice_coef: 0.8504 - tversky: 0.8416 - mean_io_u_1: 0.8384\n",
            "Epoch 65: val_loss did not improve from 0.24986\n",
            "391/391 [==============================] - 207s 529ms/step - loss: 0.2479 - recall_1: 0.7960 - precision_1: 0.8974 - dice_coef: 0.8504 - tversky: 0.8416 - mean_io_u_1: 0.8384 - val_loss: 0.2585 - val_recall_1: 0.7917 - val_precision_1: 0.8874 - val_dice_coef: 0.8415 - val_tversky: 0.8332 - val_mean_io_u_1: 0.8393 - lr: 0.0010\n",
            "Epoch 66/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2433 - recall_1: 0.7963 - precision_1: 0.8975 - dice_coef: 0.8545 - tversky: 0.8454 - mean_io_u_1: 0.8388\n",
            "Epoch 66: val_loss did not improve from 0.24986\n",
            "391/391 [==============================] - 208s 531ms/step - loss: 0.2433 - recall_1: 0.7963 - precision_1: 0.8975 - dice_coef: 0.8545 - tversky: 0.8454 - mean_io_u_1: 0.8388 - val_loss: 0.2510 - val_recall_1: 0.7902 - val_precision_1: 0.8934 - val_dice_coef: 0.8502 - val_tversky: 0.8392 - val_mean_io_u_1: 0.8367 - lr: 0.0010\n",
            "Epoch 67/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2501 - recall_1: 0.7966 - precision_1: 0.8987 - dice_coef: 0.8486 - tversky: 0.8401 - mean_io_u_1: 0.8393\n",
            "Epoch 67: val_loss did not improve from 0.24986\n",
            "391/391 [==============================] - 208s 530ms/step - loss: 0.2501 - recall_1: 0.7966 - precision_1: 0.8987 - dice_coef: 0.8486 - tversky: 0.8401 - mean_io_u_1: 0.8393 - val_loss: 0.2522 - val_recall_1: 0.7907 - val_precision_1: 0.8918 - val_dice_coef: 0.8494 - val_tversky: 0.8378 - val_mean_io_u_1: 0.8382 - lr: 0.0010\n",
            "Epoch 68/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2456 - recall_1: 0.7969 - precision_1: 0.8984 - dice_coef: 0.8522 - tversky: 0.8434 - mean_io_u_1: 0.8395\n",
            "Epoch 68: val_loss did not improve from 0.24986\n",
            "391/391 [==============================] - 209s 534ms/step - loss: 0.2456 - recall_1: 0.7969 - precision_1: 0.8984 - dice_coef: 0.8522 - tversky: 0.8434 - mean_io_u_1: 0.8395 - val_loss: 0.2626 - val_recall_1: 0.7919 - val_precision_1: 0.8897 - val_dice_coef: 0.8409 - val_tversky: 0.8301 - val_mean_io_u_1: 0.8388 - lr: 0.0010\n",
            "Epoch 69/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2483 - recall_1: 0.7973 - precision_1: 0.8985 - dice_coef: 0.8514 - tversky: 0.8419 - mean_io_u_1: 0.8398\n",
            "Epoch 69: val_loss did not improve from 0.24986\n",
            "391/391 [==============================] - 208s 530ms/step - loss: 0.2483 - recall_1: 0.7973 - precision_1: 0.8985 - dice_coef: 0.8514 - tversky: 0.8419 - mean_io_u_1: 0.8398 - val_loss: 0.2632 - val_recall_1: 0.7894 - val_precision_1: 0.8963 - val_dice_coef: 0.8425 - val_tversky: 0.8297 - val_mean_io_u_1: 0.8356 - lr: 0.0010\n",
            "Epoch 70/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2431 - recall_1: 0.7971 - precision_1: 0.9012 - dice_coef: 0.8550 - tversky: 0.8455 - mean_io_u_1: 0.8392\n",
            "Epoch 70: val_loss improved from 0.24986 to 0.24149, saving model to /content/drive/MyDrive/CT_res_att_unet_2/CT_res_att_unet.h5\n",
            "391/391 [==============================] - 210s 536ms/step - loss: 0.2431 - recall_1: 0.7971 - precision_1: 0.9012 - dice_coef: 0.8550 - tversky: 0.8455 - mean_io_u_1: 0.8392 - val_loss: 0.2415 - val_recall_1: 0.7928 - val_precision_1: 0.8908 - val_dice_coef: 0.8546 - val_tversky: 0.8465 - val_mean_io_u_1: 0.8395 - lr: 0.0010\n",
            "Epoch 71/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2454 - recall_1: 0.7976 - precision_1: 0.9000 - dice_coef: 0.8542 - tversky: 0.8441 - mean_io_u_1: 0.8399\n",
            "Epoch 71: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 207s 529ms/step - loss: 0.2454 - recall_1: 0.7976 - precision_1: 0.9000 - dice_coef: 0.8542 - tversky: 0.8441 - mean_io_u_1: 0.8399 - val_loss: 0.2504 - val_recall_1: 0.7903 - val_precision_1: 0.8904 - val_dice_coef: 0.8499 - val_tversky: 0.8399 - val_mean_io_u_1: 0.8379 - lr: 0.0010\n",
            "Epoch 72/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2419 - recall_1: 0.7978 - precision_1: 0.9012 - dice_coef: 0.8558 - tversky: 0.8464 - mean_io_u_1: 0.8399\n",
            "Epoch 72: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 209s 534ms/step - loss: 0.2419 - recall_1: 0.7978 - precision_1: 0.9012 - dice_coef: 0.8558 - tversky: 0.8464 - mean_io_u_1: 0.8399 - val_loss: 0.2737 - val_recall_1: 0.7892 - val_precision_1: 0.8923 - val_dice_coef: 0.8296 - val_tversky: 0.8208 - val_mean_io_u_1: 0.8372 - lr: 0.0010\n",
            "Epoch 73/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2488 - recall_1: 0.7981 - precision_1: 0.9012 - dice_coef: 0.8513 - tversky: 0.8412 - mean_io_u_1: 0.8406\n",
            "Epoch 73: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 207s 529ms/step - loss: 0.2488 - recall_1: 0.7981 - precision_1: 0.9012 - dice_coef: 0.8513 - tversky: 0.8412 - mean_io_u_1: 0.8406 - val_loss: 0.2577 - val_recall_1: 0.7902 - val_precision_1: 0.8950 - val_dice_coef: 0.8442 - val_tversky: 0.8340 - val_mean_io_u_1: 0.8376 - lr: 0.0010\n",
            "Epoch 74/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2484 - recall_1: 0.7981 - precision_1: 0.9026 - dice_coef: 0.8531 - tversky: 0.8422 - mean_io_u_1: 0.8405\n",
            "Epoch 74: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 208s 531ms/step - loss: 0.2484 - recall_1: 0.7981 - precision_1: 0.9026 - dice_coef: 0.8531 - tversky: 0.8422 - mean_io_u_1: 0.8405 - val_loss: 0.2529 - val_recall_1: 0.7901 - val_precision_1: 0.8906 - val_dice_coef: 0.8488 - val_tversky: 0.8379 - val_mean_io_u_1: 0.8388 - lr: 0.0010\n",
            "Epoch 75/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2414 - recall_1: 0.7984 - precision_1: 0.9019 - dice_coef: 0.8571 - tversky: 0.8470 - mean_io_u_1: 0.8410\n",
            "Epoch 75: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 207s 530ms/step - loss: 0.2414 - recall_1: 0.7984 - precision_1: 0.9019 - dice_coef: 0.8571 - tversky: 0.8470 - mean_io_u_1: 0.8410 - val_loss: 0.2593 - val_recall_1: 0.7895 - val_precision_1: 0.8920 - val_dice_coef: 0.8394 - val_tversky: 0.8310 - val_mean_io_u_1: 0.8385 - lr: 0.0010\n",
            "Epoch 76/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2455 - recall_1: 0.7982 - precision_1: 0.9036 - dice_coef: 0.8548 - tversky: 0.8440 - mean_io_u_1: 0.8406\n",
            "Epoch 76: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 209s 534ms/step - loss: 0.2455 - recall_1: 0.7982 - precision_1: 0.9036 - dice_coef: 0.8548 - tversky: 0.8440 - mean_io_u_1: 0.8406 - val_loss: 0.2581 - val_recall_1: 0.7897 - val_precision_1: 0.8918 - val_dice_coef: 0.8441 - val_tversky: 0.8336 - val_mean_io_u_1: 0.8386 - lr: 0.0010\n",
            "Epoch 77/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2437 - recall_1: 0.7986 - precision_1: 0.9031 - dice_coef: 0.8562 - tversky: 0.8453 - mean_io_u_1: 0.8414\n",
            "Epoch 77: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 207s 529ms/step - loss: 0.2437 - recall_1: 0.7986 - precision_1: 0.9031 - dice_coef: 0.8562 - tversky: 0.8453 - mean_io_u_1: 0.8414 - val_loss: 0.2580 - val_recall_1: 0.7890 - val_precision_1: 0.8941 - val_dice_coef: 0.8463 - val_tversky: 0.8344 - val_mean_io_u_1: 0.8373 - lr: 0.0010\n",
            "Epoch 78/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2467 - recall_1: 0.7986 - precision_1: 0.9041 - dice_coef: 0.8531 - tversky: 0.8430 - mean_io_u_1: 0.8406\n",
            "Epoch 78: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 208s 531ms/step - loss: 0.2467 - recall_1: 0.7986 - precision_1: 0.9041 - dice_coef: 0.8531 - tversky: 0.8430 - mean_io_u_1: 0.8406 - val_loss: 0.2566 - val_recall_1: 0.7888 - val_precision_1: 0.8922 - val_dice_coef: 0.8448 - val_tversky: 0.8343 - val_mean_io_u_1: 0.8381 - lr: 0.0010\n",
            "Epoch 79/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2439 - recall_1: 0.7989 - precision_1: 0.9039 - dice_coef: 0.8557 - tversky: 0.8449 - mean_io_u_1: 0.8413\n",
            "Epoch 79: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 207s 530ms/step - loss: 0.2439 - recall_1: 0.7989 - precision_1: 0.9039 - dice_coef: 0.8557 - tversky: 0.8449 - mean_io_u_1: 0.8413 - val_loss: 0.2563 - val_recall_1: 0.7886 - val_precision_1: 0.8919 - val_dice_coef: 0.8436 - val_tversky: 0.8345 - val_mean_io_u_1: 0.8383 - lr: 0.0010\n",
            "Epoch 80/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2452 - recall_1: 0.7988 - precision_1: 0.9056 - dice_coef: 0.8547 - tversky: 0.8441 - mean_io_u_1: 0.8410\n",
            "Epoch 80: val_loss did not improve from 0.24149\n",
            "\n",
            "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "391/391 [==============================] - 209s 534ms/step - loss: 0.2452 - recall_1: 0.7988 - precision_1: 0.9056 - dice_coef: 0.8547 - tversky: 0.8441 - mean_io_u_1: 0.8410 - val_loss: 0.2611 - val_recall_1: 0.7878 - val_precision_1: 0.8929 - val_dice_coef: 0.8445 - val_tversky: 0.8318 - val_mean_io_u_1: 0.8382 - lr: 0.0010\n",
            "Epoch 81/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2418 - recall_1: 0.7993 - precision_1: 0.9062 - dice_coef: 0.8570 - tversky: 0.8466 - mean_io_u_1: 0.8412\n",
            "Epoch 81: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 207s 529ms/step - loss: 0.2418 - recall_1: 0.7993 - precision_1: 0.9062 - dice_coef: 0.8570 - tversky: 0.8466 - mean_io_u_1: 0.8412 - val_loss: 0.2613 - val_recall_1: 0.7891 - val_precision_1: 0.8926 - val_dice_coef: 0.8426 - val_tversky: 0.8313 - val_mean_io_u_1: 0.8393 - lr: 2.0000e-04\n",
            "Epoch 82/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2419 - recall_1: 0.7996 - precision_1: 0.9060 - dice_coef: 0.8572 - tversky: 0.8464 - mean_io_u_1: 0.8416\n",
            "Epoch 82: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 208s 533ms/step - loss: 0.2419 - recall_1: 0.7996 - precision_1: 0.9060 - dice_coef: 0.8572 - tversky: 0.8464 - mean_io_u_1: 0.8416 - val_loss: 0.2609 - val_recall_1: 0.7887 - val_precision_1: 0.8931 - val_dice_coef: 0.8430 - val_tversky: 0.8317 - val_mean_io_u_1: 0.8385 - lr: 2.0000e-04\n",
            "Epoch 83/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2437 - recall_1: 0.7992 - precision_1: 0.9066 - dice_coef: 0.8564 - tversky: 0.8455 - mean_io_u_1: 0.8413\n",
            "Epoch 83: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 208s 531ms/step - loss: 0.2437 - recall_1: 0.7992 - precision_1: 0.9066 - dice_coef: 0.8564 - tversky: 0.8455 - mean_io_u_1: 0.8413 - val_loss: 0.2628 - val_recall_1: 0.7890 - val_precision_1: 0.8924 - val_dice_coef: 0.8408 - val_tversky: 0.8302 - val_mean_io_u_1: 0.8388 - lr: 2.0000e-04\n",
            "Epoch 84/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2394 - recall_1: 0.7997 - precision_1: 0.9059 - dice_coef: 0.8596 - tversky: 0.8487 - mean_io_u_1: 0.8416\n",
            "Epoch 84: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 213s 545ms/step - loss: 0.2394 - recall_1: 0.7997 - precision_1: 0.9059 - dice_coef: 0.8596 - tversky: 0.8487 - mean_io_u_1: 0.8416 - val_loss: 0.2530 - val_recall_1: 0.7885 - val_precision_1: 0.8928 - val_dice_coef: 0.8496 - val_tversky: 0.8374 - val_mean_io_u_1: 0.8389 - lr: 2.0000e-04\n",
            "Epoch 85/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2414 - recall_1: 0.7997 - precision_1: 0.9061 - dice_coef: 0.8573 - tversky: 0.8469 - mean_io_u_1: 0.8415\n",
            "Epoch 85: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 207s 530ms/step - loss: 0.2414 - recall_1: 0.7997 - precision_1: 0.9061 - dice_coef: 0.8573 - tversky: 0.8469 - mean_io_u_1: 0.8415 - val_loss: 0.2550 - val_recall_1: 0.7892 - val_precision_1: 0.8927 - val_dice_coef: 0.8477 - val_tversky: 0.8369 - val_mean_io_u_1: 0.8385 - lr: 2.0000e-04\n",
            "Epoch 86/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2433 - recall_1: 0.7994 - precision_1: 0.9060 - dice_coef: 0.8565 - tversky: 0.8457 - mean_io_u_1: 0.8415\n",
            "Epoch 86: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 208s 532ms/step - loss: 0.2433 - recall_1: 0.7994 - precision_1: 0.9060 - dice_coef: 0.8565 - tversky: 0.8457 - mean_io_u_1: 0.8415 - val_loss: 0.2615 - val_recall_1: 0.7882 - val_precision_1: 0.8936 - val_dice_coef: 0.8409 - val_tversky: 0.8305 - val_mean_io_u_1: 0.8385 - lr: 2.0000e-04\n",
            "Epoch 87/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2426 - recall_1: 0.7993 - precision_1: 0.9072 - dice_coef: 0.8569 - tversky: 0.8464 - mean_io_u_1: 0.8413\n",
            "Epoch 87: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 208s 531ms/step - loss: 0.2426 - recall_1: 0.7993 - precision_1: 0.9072 - dice_coef: 0.8569 - tversky: 0.8464 - mean_io_u_1: 0.8413 - val_loss: 0.2664 - val_recall_1: 0.7883 - val_precision_1: 0.8939 - val_dice_coef: 0.8365 - val_tversky: 0.8268 - val_mean_io_u_1: 0.8377 - lr: 2.0000e-04\n",
            "Epoch 88/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2440 - recall_1: 0.7999 - precision_1: 0.9065 - dice_coef: 0.8544 - tversky: 0.8442 - mean_io_u_1: 0.8417\n",
            "Epoch 88: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 208s 532ms/step - loss: 0.2440 - recall_1: 0.7999 - precision_1: 0.9065 - dice_coef: 0.8544 - tversky: 0.8442 - mean_io_u_1: 0.8417 - val_loss: 0.2565 - val_recall_1: 0.7874 - val_precision_1: 0.8933 - val_dice_coef: 0.8446 - val_tversky: 0.8353 - val_mean_io_u_1: 0.8375 - lr: 2.0000e-04\n",
            "Epoch 89/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2415 - recall_1: 0.7999 - precision_1: 0.9061 - dice_coef: 0.8566 - tversky: 0.8468 - mean_io_u_1: 0.8414\n",
            "Epoch 89: val_loss did not improve from 0.24149\n",
            "391/391 [==============================] - 207s 528ms/step - loss: 0.2415 - recall_1: 0.7999 - precision_1: 0.9061 - dice_coef: 0.8566 - tversky: 0.8468 - mean_io_u_1: 0.8414 - val_loss: 0.2586 - val_recall_1: 0.7886 - val_precision_1: 0.8939 - val_dice_coef: 0.8447 - val_tversky: 0.8334 - val_mean_io_u_1: 0.8389 - lr: 2.0000e-04\n",
            "Epoch 90/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2450 - recall_1: 0.7996 - precision_1: 0.9072 - dice_coef: 0.8550 - tversky: 0.8443 - mean_io_u_1: 0.8415\n",
            "Epoch 90: val_loss did not improve from 0.24149\n",
            "\n",
            "Epoch 90: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "391/391 [==============================] - 211s 540ms/step - loss: 0.2450 - recall_1: 0.7996 - precision_1: 0.9072 - dice_coef: 0.8550 - tversky: 0.8443 - mean_io_u_1: 0.8415 - val_loss: 0.2620 - val_recall_1: 0.7886 - val_precision_1: 0.8931 - val_dice_coef: 0.8435 - val_tversky: 0.8317 - val_mean_io_u_1: 0.8388 - lr: 2.0000e-04\n",
            "Epoch 90: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe55054d8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ids = list(Xtest.image_path)\n",
        "test_mask = list(Xtest.mask_path)\n",
        "test_data = DataGenerator(test_ids, test_mask)\n",
        "\n",
        "#Recall(), Precision(),dice_coef,tversky, MeanIoU(num_classes=6)"
      ],
      "metadata": {
        "id": "1-hq-bkulMQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rcall ,pre ,dice,tv ,men= Res_Unet_model.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "Pr1KAw44l-aA",
        "outputId": "c323ef95-660d-4a27-f4ad-6245b3a4d1e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 110s 3s/step - loss: 0.2527 - recall: 0.7891 - precision: 0.8952 - dice_coef: 0.8490 - tversky: 0.8383 - mean_io_u: 0.8414\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c688499716d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrcall\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mpre\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtv\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mmen\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mRes_Unet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 5)"
          ]
        }
      ]
    }
  ]
}