{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResUnetAttentionipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QawvgeYEYaI8"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input,Conv2D, Conv3D, MaxPooling3D,UpSampling2D, UpSampling3D,MaxPooling2D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate,Add\n",
        "import keras as Ks\n",
        "from keras.layers import Input\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from skimage import io\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.metrics import Precision, Recall, MeanIoU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGWPD-JSQ9pD",
        "outputId": "932a23e8-5e80-4f4c-c4fc-7eb01684048f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --no-cache-dir gdown --pre\n",
        "!gdown --id 1-2HGO0znF0JAsgZ_et5Cr_owKVxr_bKZ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioCsI4LEOFPK",
        "outputId": "33187cfe-f441-43e1-e180-5055f8f86ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14774 sha256=9201dfc3deaf62dd7c2043647ce5a1e3fd720bbd5571ca0c6e0328c8a61a3ca3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oox6g631/wheels/fb/c3/0e/c4d8ff8bfcb0461afff199471449f642179b74968c15b7a69c\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.2.2\n",
            "    Uninstalling gdown-4.2.2:\n",
            "      Successfully uninstalled gdown-4.2.2\n",
            "Successfully installed gdown-4.4.0\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-2HGO0znF0JAsgZ_et5Cr_owKVxr_bKZ\n",
            "To: /content/CT_Data.zip\n",
            "100% 624M/624M [00:03<00:00, 197MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1-2HGO0znF0JAsgZ_et5Cr_owKVxr_bKZ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km7lnals4d1-",
        "outputId": "041fd269-2c8a-432a-ef5d-854972247043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-2HGO0znF0JAsgZ_et5Cr_owKVxr_bKZ\n",
            "To: /content/CT_Data.zip\n",
            "100% 624M/624M [00:03<00:00, 194MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "file_name=\"/content/CT_Data.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as ziip:\n",
        "  ziip.extractall()\n",
        "  print('woow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nernz1QdOWP4",
        "outputId": "061e3d90-4975-4948-803b-96c620892f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "woow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_files = glob('/content/content/drive/MyDrive/CT_Data/Masks/*')\n",
        "len(mask_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QV-NzPMOzO6",
        "outputId": "76a17a71-77c1-4a58-b845-6e9f7af4af2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7367"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CT = glob('/content/content/drive/MyDrive/CT_Data/CT_images/*')\n",
        "len(CT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nlq7CVflO71j",
        "outputId": "5f2f8e0c-45d4-4aa6-e82b-dcd1910fffff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7367"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"image_path\": CT, \"mask_path\":mask_files})\n"
      ],
      "metadata": {
        "id": "ZnM6sPBsPES9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xval = train_test_split(df, test_size=0.15)\n",
        "Xtest, Xval = train_test_split(Xval, test_size=0.5)\n",
        "print(\"Train size is {}, valid size is {} & test size is {}\".format(len(Xtrain), len(Xval), len(Xtest)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCGWJCIdPZ-l",
        "outputId": "04d42829-1c6a-47b7-fa4c-3a1ca9254de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size is 6261, valid size is 553 & test size is 553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ids = list(Xtrain.image_path)\n",
        "train_mask = list(Xtrain.mask_path)\n",
        "\n",
        "val_ids = list(Xval.image_path)\n",
        "val_mask= list(Xval.mask_path)"
      ],
      "metadata": {
        "id": "c_nfcfIgQM53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tversky(ytrue, ypred):\n",
        "    ypredpos = K.flatten(ypred)\n",
        "    ytruepos = K.flatten(ytrue)\n",
        "    truepos = K.sum(ytruepos * ypredpos)\n",
        "    falseneg = K.sum(ytruepos * (1-ypredpos))\n",
        "    falsepos = K.sum((1-ytruepos)*ypredpos)\n",
        "    alpha = 0.7\n",
        "    smooth=100\n",
        "    return (truepos + smooth)/(truepos + alpha*falseneg + (1-alpha)*falsepos + smooth)\n",
        "\n",
        "def focaltversky(ytrue,ypred):\n",
        "    ypred = tf.cast(ypred, tf.float32)\n",
        "    ytrue = tf.cast(ytrue, tf.float32)\n",
        "    \n",
        "    pt_1 = tversky(ytrue, ypred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)\n",
        "\n",
        "def tversky_loss(ytrue, ypred):\n",
        "    return 1 - tversky(ytrue,ypred)"
      ],
      "metadata": {
        "id": "oiskjv6sPtp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resblock(X, f):\n",
        " \n",
        "    Xcopy = X  \n",
        "    \n",
        "    # main path\n",
        "    X = Conv2D(f, kernel_size=(1,1), kernel_initializer='he_normal')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(f, kernel_size=(3,3), padding='same', kernel_initializer='he_normal')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    \n",
        "    # shortcut path\n",
        "    Xcopy = Conv2D(f, kernel_size=(1,1), kernel_initializer='he_normal')(Xcopy)\n",
        "    Xcopy = BatchNormalization()(Xcopy)\n",
        "    \n",
        "    # Adding the output from main path and short path together\n",
        "    X = Add()([X, Xcopy])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X\n",
        "\n",
        "def attention_block(L,X ,numfilters):\n",
        "    ## Getting shapes if the layers\n",
        "    shape_X=X.shape\n",
        "    shape_L=L.shape\n",
        "\n",
        "    ## getting x to the same shape as L\n",
        "    theta_x=Conv2D(numfilters,(1,1),strides=(1,1),padding=\"same\")(X)\n",
        "    shape_X_theta=theta_x.shape\n",
        "    phy_L=Conv2D(numfilters,(1,1),strides=(2,2),padding=\"same\")(L)\n",
        "    shape_L_phy=phy_L.shape\n",
        "    ##Adding the 2 layers together\n",
        "    XL= Ks.layers.add([theta_x,phy_L])\n",
        "    activate_XL=Ks.layers.Activation('relu')(XL)\n",
        "    conv=Conv2D(1,(1,1),padding='same')(activate_XL)\n",
        "    \n",
        "    act_sigmoid=Ks.layers.Activation('sigmoid')(conv)\n",
        "    shape_sig=act_sigmoid.shape\n",
        "    ##upsampling \n",
        "    upsampled=Ks.layers.UpSampling2D(size=(shape_L[1]//shape_sig[1],shape_L[2]//shape_sig[2]))(act_sigmoid)\n",
        "\n",
        "    #output\n",
        "    y=Ks.layers.multiply([upsampled,L])\n",
        "    out=Conv2D(shape_L[3],(1,1),padding='same')(y)\n",
        "    return out\n",
        "\n",
        "\n",
        "def upsample_concat_with_attention_block(x, skip,num_filters):\n",
        "    '''\n",
        "    funtion for upsampling image\n",
        "    '''\n",
        "    m=attention_block(skip,x,num_filters)\n",
        "    S= UpSampling2D((2,2))(x)\n",
        "    # X= Concatenate()([S,skip])\n",
        "    \n",
        "    merge = Concatenate()([m,S])\n",
        "    \n",
        "    return merge"
      ],
      "metadata": {
        "id": "jBhfaQA8Y2ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Res_Unet_with_att_model(inputshape=(256,256,3),filter_num=8,pool_size=(2, 2),n_classes=3):\n",
        "  Xinput = Input(inputshape)\n",
        "\n",
        "  conv_1 = Conv2D(2*filter_num, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(Xinput)\n",
        "  conv_1 = BatchNormalization()(conv_1)\n",
        "  conv_1 = Conv2D(2*filter_num, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv_1)\n",
        "  conv_1 = BatchNormalization()(conv_1)\n",
        "  pool_1 = MaxPool2D(pool_size)(conv_1)\n",
        "\n",
        "\n",
        "  conv_2 = resblock(pool_1, 4*filter_num)\n",
        "  pool_2 = MaxPooling2D(pool_size)(conv_2)\n",
        "\n",
        "\n",
        "  conv_3 = resblock(pool_2, 8*filter_num)\n",
        "  pool_3 = MaxPooling2D(pool_size)(conv_3)\n",
        "\n",
        "\n",
        "  conv_4 = resblock(pool_3, 16*filter_num)\n",
        "  pool_4 = MaxPooling2D(pool_size)(conv_4)\n",
        "\n",
        "\n",
        "  conv_5 = resblock(pool_4, 32*filter_num)\n",
        "\n",
        "\n",
        "  up_1 = upsample_concat_with_attention_block(conv_5, conv_4,16*filter_num)\n",
        "  up_1 = resblock(up_1, 16*filter_num)\n",
        "\n",
        "\n",
        "  up_2 = upsample_concat_with_attention_block(up_1, conv_3,8*filter_num)\n",
        "  up_2 = resblock(up_2, 8*filter_num)\n",
        "\n",
        "\n",
        "  up_3 = upsample_concat_with_attention_block(up_2, conv_2,4*filter_num)\n",
        "  up_3 = resblock(up_3, 4*filter_num)\n",
        "\n",
        "\n",
        "  up_4 = upsample_concat_with_attention_block(up_3, conv_1,2*filter_num)\n",
        "  up_4 = resblock(up_4, 2*filter_num)\n",
        "\n",
        "\n",
        "  out = Conv2D(n_classes, (1,1), kernel_initializer='he_normal', padding='same', activation='sigmoid')(up_4)\n",
        "  Res_Unet_with_att_model=Model(Xinput, out)\n",
        "  return Res_Unet_with_att_model"
      ],
      "metadata": {
        "id": "30cVXDmaZCm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputshape = (256,256,3)\n",
        "Res_Unet_model=Res_Unet_with_att_model(inputshape,filter_num=16)"
      ],
      "metadata": {
        "id": "s6u3VG5V4NW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Res_Unet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgecCgXTZ9bb",
        "outputId": "bd95e63a-7990-4de5-a47a-b303bf6bd6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 32  896         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 256, 256, 32  128        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 32  9248        ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 256, 256, 32  128        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 64  2112        ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 64  256        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 128, 128, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 64  36928       ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 64  2112        ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 128, 64  256        ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128, 128, 64  256        ['conv2d_4[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 128, 128, 64  0           ['batch_normalization_3[0][0]',  \n",
            "                                )                                 'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 128, 128, 64  0           ['add[0][0]']                    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)  0           ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 128)  8320        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 64, 64, 128)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 64, 64, 128)  147584      ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 64, 64, 128)  8320        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 64, 64, 128)  0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 64, 64, 128)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0          ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 256)  33024       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 32, 32, 256)  0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 256)  590080      ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 256)  33024       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 256)  0           ['batch_normalization_9[0][0]',  \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 256)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 512)  131584      ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 512)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 512)  2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 512)  131584      ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 512)  0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 512)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 256)  131328      ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 256)  65792       ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 16, 16, 256)  0           ['conv2d_14[0][0]',              \n",
            "                                                                  'conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 256)  0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 1)    257         ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 1)    0           ['conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 32, 32, 1)    0           ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 32, 32, 256)  0           ['up_sampling2d[0][0]',          \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 32, 32, 256)  65792       ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 512)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 768)  0           ['conv2d_17[0][0]',              \n",
            "                                                                  'up_sampling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 32, 32, 256)  196864      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 32, 32, 256)  196864      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 32, 32, 256)  0           ['batch_normalization_15[0][0]', \n",
            "                                                                  'batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 32, 32, 256)  0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 32, 32, 128)  32896       ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 32, 32, 128)  16512       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 32, 32, 128)  0           ['conv2d_21[0][0]',              \n",
            "                                                                  'conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 32, 32, 128)  0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 32, 32, 1)    129         ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 32, 32, 1)    0           ['conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 1)   0           ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 64, 64, 128)  0           ['up_sampling2d_2[0][0]',        \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 64, 64, 128)  16512       ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 256)  0          ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 384)  0           ['conv2d_24[0][0]',              \n",
            "                                                                  'up_sampling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 64, 64, 128)  49280       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 64, 64, 128)  512        ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 64, 64, 128)  49280       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 64, 64, 128)  512        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 64, 64, 128)  512        ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 64, 64, 128)  0           ['batch_normalization_18[0][0]', \n",
            "                                                                  'batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 64, 64, 128)  0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 64, 64, 64)   8256        ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 64, 64, 64)   4160        ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 64, 64, 64)   0           ['conv2d_28[0][0]',              \n",
            "                                                                  'conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 64, 64, 64)   0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 64, 64, 1)    65          ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 64, 64, 1)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 1)  0          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 128, 128, 64  0           ['up_sampling2d_4[0][0]',        \n",
            "                                )                                 'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 128, 128, 64  4160        ['multiply_2[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 12  0          ['activation_15[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 19  0           ['conv2d_31[0][0]',              \n",
            "                                2)                                'up_sampling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 128, 128, 64  12352       ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 128, 128, 64  256        ['conv2d_32[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_20[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 128, 128, 64  36928       ['activation_18[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 128, 128, 64  12352       ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 128, 128, 64  256        ['conv2d_33[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 128, 128, 64  256        ['conv2d_34[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 128, 128, 64  0           ['batch_normalization_21[0][0]', \n",
            "                                )                                 'batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 128, 128, 64  0           ['add_9[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 128, 128, 32  2080        ['activation_19[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 128, 128, 32  1056        ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 128, 128, 32  0           ['conv2d_35[0][0]',              \n",
            "                                )                                 'conv2d_36[0][0]']              \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 128, 128, 32  0           ['add_10[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 128, 128, 1)  33          ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 128, 128, 1)  0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 1)  0          ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 256, 256, 32  0           ['up_sampling2d_6[0][0]',        \n",
            "                                )                                 'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 256, 256, 32  1056        ['multiply_3[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 64  0          ['activation_19[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 96  0           ['conv2d_38[0][0]',              \n",
            "                                )                                 'up_sampling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 256, 256, 32  3104        ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 256, 256, 32  128        ['conv2d_39[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 256, 256, 32  0           ['batch_normalization_23[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 256, 256, 32  9248        ['activation_22[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 256, 256, 32  3104        ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 256, 256, 32  128        ['conv2d_40[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 256, 256, 32  128        ['conv2d_41[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 256, 256, 32  0           ['batch_normalization_24[0][0]', \n",
            "                                )                                 'batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 256, 256, 32  0           ['add_11[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 256, 256, 3)  99          ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,169,383\n",
            "Trainable params: 5,160,615\n",
            "Non-trainable params: 8,768\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def __init__(self, ids , mask, image_dir = './', batch_size = 16, img_h = 256, img_w = 256, shuffle = True):\n",
        "    self.ids = ids\n",
        "    self.mask = mask\n",
        "    self.image_dir = image_dir\n",
        "    self.batch_size = batch_size\n",
        "    self.img_h = img_h\n",
        "    self.img_w = img_w\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.ids)) / self.batch_size)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    indexes = self.indexes[index* self.batch_size : (index+1) * self.batch_size]\n",
        "    list_ids = [self.ids[i] for i in indexes]\n",
        "    list_mask = [self.mask[i] for i in indexes]\n",
        "    X, y = self.__data_generation(list_ids, list_mask)\n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):    \n",
        "    self.indexes = np.arange(len(self.ids))\n",
        "\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __data_generation(self, list_ids, list_mask):\n",
        "\n",
        "    X = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n",
        "    y = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n",
        "\n",
        "    for i in range(len(list_ids)):\n",
        "      img_path = str(list_ids[i])\n",
        "      mask_path = str(list_mask[i])\n",
        "      img = io.imread(img_path)\n",
        "      mask = io.imread(mask_path)\n",
        "      img = cv2.resize(img,(self.img_h,self.img_w))\n",
        "      img = np.array(img, dtype = np.float64)\n",
        "      mask = cv2.resize(mask,(self.img_h,self.img_w))\n",
        "      mask = np.array(mask, dtype = np.float64)\n",
        "      img -= img.mean()\n",
        "      img /= img.std()\n",
        "      mask -= mask.mean()\n",
        "      mask /= mask.std()\n",
        "      X[i,] = img\n",
        "      y[i,] = mask\n",
        "    y = (y > 0).astype(int)\n",
        "    return X, y\n",
        "\n",
        "train_data = DataGenerator(train_ids, train_mask)\n",
        "val_data = DataGenerator(val_ids, val_mask)"
      ],
      "metadata": {
        "id": "3VJ_bEqZ9oca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystopping = EarlyStopping(monitor='val_loss',\n",
        "                              mode='min', \n",
        "                              verbose=1, \n",
        "                              patience=20\n",
        "                             )\n",
        "checkpointer = ModelCheckpoint(filepath=\"/content/drive/MyDrive/CT_res_att_unet/CT_res_att_unet.h5\", \n",
        "                               verbose=1, \n",
        "                               save_best_only=True\n",
        "                              )\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              mode='min',\n",
        "                              verbose=1,\n",
        "                              patience=10,\n",
        "                              min_delta=0.0001,\n",
        "                              factor=0.2\n",
        "                             )\n",
        "filename='/content/drive/MyDrive/CT_res_att_unet/history.csv'\n",
        "history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)"
      ],
      "metadata": {
        "id": "QXaO0qZ6QvyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam(lr = 0.02, epsilon = 0.1)\n",
        "Res_Unet_model.compile(optimizer = adam, \n",
        "                  loss = focaltversky, \n",
        "                  metrics = [Recall(), Precision(), tversky, MeanIoU(num_classes=3)]\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQlKuaVqQaZb",
        "outputId": "c3efa301-3873-431e-e1e7-d5d7fcd23868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Res_Unet_model.load_weights(\"/content/drive/MyDrive/CT_res_att_unet/CT_res_att_unet.h5\")"
      ],
      "metadata": {
        "id": "l8hoDyB8bajD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Res_Unet_model.fit(train_data, \n",
        "                  epochs = 200,\n",
        "                  initial_epoch=33,\n",
        "                  validation_data = val_data,\n",
        "                  callbacks = [checkpointer, earlystopping, reduce_lr,history_logger]\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0sJF49FRn_5",
        "outputId": "108a1442-3e38-4fbc-d189-f13a5ca4f1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - ETA: 0s - loss: 0.9007 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1266 - mean_io_u_1: 0.4997\n",
            "Epoch 34: val_loss improved from inf to 0.91124, saving model to /content/drive/MyDrive/CT_res_att_unet/CT_res_att_unet.h5\n",
            "391/391 [==============================] - 375s 946ms/step - loss: 0.9007 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1266 - mean_io_u_1: 0.4997 - val_loss: 0.9112 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1156 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 35/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9119 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1133 - mean_io_u_1: 0.4997\n",
            "Epoch 35: val_loss did not improve from 0.91124\n",
            "391/391 [==============================] - 369s 944ms/step - loss: 0.9119 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1133 - mean_io_u_1: 0.4997 - val_loss: 0.9213 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1028 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 36/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9038 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1230 - mean_io_u_1: 0.4997\n",
            "Epoch 36: val_loss improved from 0.91124 to 0.90060, saving model to /content/drive/MyDrive/CT_res_att_unet/CT_res_att_unet.h5\n",
            "391/391 [==============================] - 370s 945ms/step - loss: 0.9038 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1230 - mean_io_u_1: 0.4997 - val_loss: 0.9006 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1284 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 37/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9025 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1237 - mean_io_u_1: 0.4997\n",
            "Epoch 37: val_loss did not improve from 0.90060\n",
            "391/391 [==============================] - 367s 939ms/step - loss: 0.9025 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1237 - mean_io_u_1: 0.4997 - val_loss: 0.9227 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1010 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 38/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9056 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1200 - mean_io_u_1: 0.4997\n",
            "Epoch 38: val_loss did not improve from 0.90060\n",
            "391/391 [==============================] - 368s 942ms/step - loss: 0.9056 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1200 - mean_io_u_1: 0.4997 - val_loss: 0.9206 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1033 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 39/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8934 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1335 - mean_io_u_1: 0.4997\n",
            "Epoch 39: val_loss did not improve from 0.90060\n",
            "391/391 [==============================] - 368s 941ms/step - loss: 0.8934 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1335 - mean_io_u_1: 0.4997 - val_loss: 0.9245 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.0989 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 40/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9046 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1212 - mean_io_u_1: 0.4997\n",
            "Epoch 40: val_loss did not improve from 0.90060\n",
            "391/391 [==============================] - 367s 937ms/step - loss: 0.9046 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1212 - mean_io_u_1: 0.4997 - val_loss: 0.9185 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1063 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 41/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9020 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1244 - mean_io_u_1: 0.4997\n",
            "Epoch 41: val_loss did not improve from 0.90060\n",
            "391/391 [==============================] - 367s 939ms/step - loss: 0.9020 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1244 - mean_io_u_1: 0.4997 - val_loss: 0.9194 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1050 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 42/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9049 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1210 - mean_io_u_1: 0.4997\n",
            "Epoch 42: val_loss improved from 0.90060 to 0.89860, saving model to /content/drive/MyDrive/CT_res_att_unet/CT_res_att_unet.h5\n",
            "391/391 [==============================] - 370s 946ms/step - loss: 0.9049 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1210 - mean_io_u_1: 0.4997 - val_loss: 0.8986 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1237 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 43/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9083 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1180 - mean_io_u_1: 0.4997\n",
            "Epoch 43: val_loss did not improve from 0.89860\n",
            "391/391 [==============================] - 369s 944ms/step - loss: 0.9083 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1180 - mean_io_u_1: 0.4997 - val_loss: 0.9090 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1180 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 44/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9049 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1209 - mean_io_u_1: 0.4997\n",
            "Epoch 44: val_loss improved from 0.89860 to 0.87286, saving model to /content/drive/MyDrive/CT_res_att_unet/CT_res_att_unet.h5\n",
            "391/391 [==============================] - 368s 941ms/step - loss: 0.9049 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1209 - mean_io_u_1: 0.4997 - val_loss: 0.8729 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1544 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 45/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8996 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1265 - mean_io_u_1: 0.4997\n",
            "Epoch 45: val_loss did not improve from 0.87286\n",
            "391/391 [==============================] - 366s 937ms/step - loss: 0.8996 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1265 - mean_io_u_1: 0.4997 - val_loss: 0.9049 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1226 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 46/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9030 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1231 - mean_io_u_1: 0.4997\n",
            "Epoch 46: val_loss did not improve from 0.87286\n",
            "391/391 [==============================] - 366s 936ms/step - loss: 0.9030 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1231 - mean_io_u_1: 0.4997 - val_loss: 0.9047 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1236 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 47/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9036 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1226 - mean_io_u_1: 0.4997\n",
            "Epoch 47: val_loss did not improve from 0.87286\n",
            "391/391 [==============================] - 367s 939ms/step - loss: 0.9036 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1226 - mean_io_u_1: 0.4997 - val_loss: 0.9114 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1152 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 48/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9054 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1211 - mean_io_u_1: 0.4997\n",
            "Epoch 48: val_loss did not improve from 0.87286\n",
            "391/391 [==============================] - 366s 937ms/step - loss: 0.9054 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1211 - mean_io_u_1: 0.4997 - val_loss: 0.9279 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.0946 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 49/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9042 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1217 - mean_io_u_1: 0.4997\n",
            "Epoch 49: val_loss did not improve from 0.87286\n",
            "391/391 [==============================] - 368s 940ms/step - loss: 0.9042 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1217 - mean_io_u_1: 0.4997 - val_loss: 0.8852 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1398 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 50/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8968 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1291 - mean_io_u_1: 0.4997\n",
            "Epoch 50: val_loss did not improve from 0.87286\n",
            "391/391 [==============================] - 369s 942ms/step - loss: 0.8968 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1291 - mean_io_u_1: 0.4997 - val_loss: 0.9043 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1242 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 51/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9083 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1177 - mean_io_u_1: 0.4997\n",
            "Epoch 51: val_loss did not improve from 0.87286\n",
            "391/391 [==============================] - 369s 943ms/step - loss: 0.9083 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1177 - mean_io_u_1: 0.4997 - val_loss: 0.9082 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1179 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 52/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8937 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1321 - mean_io_u_1: 0.4997\n",
            "Epoch 52: val_loss did not improve from 0.87286\n",
            "391/391 [==============================] - 368s 941ms/step - loss: 0.8937 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1321 - mean_io_u_1: 0.4997 - val_loss: 0.8931 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1303 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 53/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8985 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1280 - mean_io_u_1: 0.4997\n",
            "Epoch 53: val_loss did not improve from 0.87286\n",
            "391/391 [==============================] - 368s 940ms/step - loss: 0.8985 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1280 - mean_io_u_1: 0.4997 - val_loss: 0.8837 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1413 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 54/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9084 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1173 - mean_io_u_1: 0.4997\n",
            "Epoch 54: val_loss did not improve from 0.87286\n",
            "\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.003999999910593033.\n",
            "391/391 [==============================] - 368s 942ms/step - loss: 0.9084 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1173 - mean_io_u_1: 0.4997 - val_loss: 0.8953 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1344 - val_mean_io_u_1: 0.4997 - lr: 0.0200\n",
            "Epoch 55/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9014 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1254 - mean_io_u_1: 0.4997\n",
            "Epoch 55: val_loss did not improve from 0.87286\n",
            "391/391 [==============================] - 369s 942ms/step - loss: 0.9014 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1254 - mean_io_u_1: 0.4997 - val_loss: 0.8918 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1383 - val_mean_io_u_1: 0.4997 - lr: 0.0040\n",
            "Epoch 56/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9016 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1238 - mean_io_u_1: 0.4997\n",
            "Epoch 56: val_loss did not improve from 0.87286\n",
            "391/391 [==============================] - 367s 937ms/step - loss: 0.9016 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1238 - mean_io_u_1: 0.4997 - val_loss: 0.9271 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.0954 - val_mean_io_u_1: 0.4997 - lr: 0.0040\n",
            "Epoch 57/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8957 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1309 - mean_io_u_1: 0.4997\n",
            "Epoch 57: val_loss did not improve from 0.87286\n",
            "391/391 [==============================] - 367s 938ms/step - loss: 0.8957 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1309 - mean_io_u_1: 0.4997 - val_loss: 0.9138 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1121 - val_mean_io_u_1: 0.4997 - lr: 0.0040\n",
            "Epoch 58/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9086 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1166 - mean_io_u_1: 0.4997\n",
            "Epoch 58: val_loss improved from 0.87286 to 0.86985, saving model to /content/drive/MyDrive/CT_res_att_unet/CT_res_att_unet.h5\n",
            "391/391 [==============================] - 369s 943ms/step - loss: 0.9086 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1166 - mean_io_u_1: 0.4997 - val_loss: 0.8698 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1562 - val_mean_io_u_1: 0.4997 - lr: 0.0040\n",
            "Epoch 59/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9092 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1165 - mean_io_u_1: 0.4997\n",
            "Epoch 59: val_loss did not improve from 0.86985\n",
            "391/391 [==============================] - 367s 937ms/step - loss: 0.9092 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1165 - mean_io_u_1: 0.4997 - val_loss: 0.9143 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1112 - val_mean_io_u_1: 0.4997 - lr: 0.0040\n",
            "Epoch 60/200\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9030 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1223 - mean_io_u_1: 0.4997\n",
            "Epoch 60: val_loss did not improve from 0.86985\n",
            "391/391 [==============================] - 364s 932ms/step - loss: 0.9030 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1223 - mean_io_u_1: 0.4997 - val_loss: 0.8908 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - val_tversky: 0.1336 - val_mean_io_u_1: 0.4997 - lr: 0.0040\n",
            "Epoch 61/200\n",
            " 20/391 [>.............................] - ETA: 5:38 - loss: 0.8860 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00 - tversky: 0.1343 - mean_io_u_1: 0.4997"
          ]
        }
      ]
    }
  ]
}