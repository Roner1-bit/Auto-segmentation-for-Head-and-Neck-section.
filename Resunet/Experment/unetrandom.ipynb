{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvufTbqwrPPe"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input,Conv2D, Conv3D, MaxPooling3D,UpSampling2D, UpSampling3D,MaxPooling2D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate,Add\n",
        "import keras as Ks\n",
        "from keras.layers import Input\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from skimage import io\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.metrics import Precision, Recall, MeanIoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFS1Q2ZNsDOV",
        "outputId": "d178afff-dbc0-434d-bf0f-9ce7766aa421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3nDGeLFsGI3",
        "outputId": "f0b6c944-a886-4dcf-90e8-0d30254f3773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14774 sha256=9c88a38815eadd9a2a167a3a93b2972f190808edb210ef10bcdc053a93981528\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cfps7f5p/wheels/fb/c3/0e/c4d8ff8bfcb0461afff199471449f642179b74968c15b7a69c\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.2.2\n",
            "    Uninstalling gdown-4.2.2:\n",
            "      Successfully uninstalled gdown-4.2.2\n",
            "Successfully installed gdown-4.4.0\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-2HGO0znF0JAsgZ_et5Cr_owKVxr_bKZ\n",
            "To: /content/CT_Data.zip\n",
            "100% 624M/624M [00:07<00:00, 82.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install -U --no-cache-dir gdown --pre\n",
        "!gdown --id 1-2HGO0znF0JAsgZ_et5Cr_owKVxr_bKZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR2UcxzTsKDu",
        "outputId": "36fafbd3-e6b9-47aa-f9b2-22e254292eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "woow\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "file_name=\"/content/CT_Data.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as ziip:\n",
        "  ziip.extractall()\n",
        "  print('woow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEPXi5ZdsNjJ",
        "outputId": "c80cb6be-d823-47ab-cf3f-8a75d10ad597"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7367"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "mask_files = glob('/content/content/drive/MyDrive/CT_Data/Masks/*')\n",
        "len(mask_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsuZKPLgsORS",
        "outputId": "607266b6-fbb7-435b-b2dd-b0ffa142695d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7367"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "CT = glob('/content/content/drive/MyDrive/CT_Data/CT_images/*')\n",
        "len(CT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKI7H-MysRiC"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"image_path\": CT, \"mask_path\":mask_files})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38Q58D8_sUR4",
        "outputId": "485ff298-5691-4eb0-da91-ae875f1f258a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size is 6261, valid size is 553 & test size is 553\n"
          ]
        }
      ],
      "source": [
        "Xtrain, Xval = train_test_split(df, test_size=0.15,random_state=101)\n",
        "Xtest, Xval = train_test_split(Xval, test_size=0.5)\n",
        "print(\"Train size is {}, valid size is {} & test size is {}\".format(len(Xtrain), len(Xval), len(Xtest)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSTH3P14sWGX"
      },
      "outputs": [],
      "source": [
        "train_ids = list(Xtrain.image_path)\n",
        "train_mask = list(Xtrain.mask_path)\n",
        "\n",
        "val_ids = list(Xval.image_path)\n",
        "val_mask= list(Xval.mask_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W7n9UBQrHe1"
      },
      "outputs": [],
      "source": [
        "def resblock(X, f):\n",
        " \n",
        "    Xcopy = X  \n",
        "    \n",
        "    # main path\n",
        "    X = Conv2D(f, kernel_size=(1,1), kernel_initializer='he_normal')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(f, kernel_size=(3,3), padding='same', kernel_initializer='he_normal')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    \n",
        "    # shortcut path\n",
        "    Xcopy = Conv2D(f, kernel_size=(1,1), kernel_initializer='he_normal')(Xcopy)\n",
        "    Xcopy = BatchNormalization()(Xcopy)\n",
        "    \n",
        "    # Adding the output from main path and short path together\n",
        "    X = Add()([X, Xcopy])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X\n",
        "\n",
        "def upsample_concat(x, skip):\n",
        "    '''\n",
        "    funtion for upsampling image\n",
        "    '''\n",
        "    X = UpSampling2D((2,2))(x)\n",
        "    merge = Concatenate()([X, skip])\n",
        "    \n",
        "    return merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT4UktRKsha-"
      },
      "outputs": [],
      "source": [
        "def tversky(ytrue, ypred):\n",
        "    ypredpos = K.flatten(ypred)\n",
        "    ytruepos = K.flatten(ytrue)\n",
        "    truepos = K.sum(ytruepos * ypredpos)\n",
        "    falseneg = K.sum(ytruepos * (1-ypredpos))\n",
        "    falsepos = K.sum((1-ytruepos)*ypredpos)\n",
        "    alpha = 0.7\n",
        "    smooth=100\n",
        "    return (truepos + smooth)/(truepos + alpha*falseneg + (1-alpha)*falsepos + smooth)\n",
        "\n",
        "def focaltversky(ytrue,ypred):\n",
        "    ypred = tf.cast(ypred, tf.float32)\n",
        "    ytrue = tf.cast(ytrue, tf.float32)\n",
        "    \n",
        "    pt_1 = tversky(ytrue, ypred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)\n",
        "\n",
        "def tversky_loss(ytrue, ypred):\n",
        "    return 1 - tversky(ytrue,ypred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51NK1WlerXtN"
      },
      "outputs": [],
      "source": [
        "def Res_Unet_model(inputshape=(256,256,3),filter_num=8,pool_size=(2, 2),n_classes=3):\n",
        "  Xinput = Input(inputshape)\n",
        "\n",
        "  conv_1 = Conv2D(2*filter_num, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(Xinput)\n",
        "  conv_1 = BatchNormalization()(conv_1)\n",
        "  conv_1 = Conv2D(2*filter_num, (3,3), activation='relu', padding='same', kernel_initializer='he_normal')(conv_1)\n",
        "  conv_1 = BatchNormalization()(conv_1)\n",
        "  pool_1 = MaxPool2D(pool_size)(conv_1)\n",
        "\n",
        "\n",
        "  conv_2 = resblock(pool_1, 4*filter_num)\n",
        "  pool_2 = MaxPooling2D(pool_size)(conv_2)\n",
        "\n",
        "\n",
        "  conv_3 = resblock(pool_2, 8*filter_num)\n",
        "  pool_3 = MaxPooling2D(pool_size)(conv_3)\n",
        "\n",
        "\n",
        "  conv_4 = resblock(pool_3, 16*filter_num)\n",
        "  pool_4 = MaxPooling2D(pool_size)(conv_4)\n",
        "\n",
        "\n",
        "  conv_5 = resblock(pool_4, 32*filter_num)\n",
        "\n",
        "\n",
        "  up_1 = upsample_concat(conv_5, conv_4)\n",
        "  up_1 = resblock(up_1, 16*filter_num)\n",
        "\n",
        "\n",
        "  up_2 = upsample_concat(up_1, conv_3)\n",
        "  up_2 = resblock(up_2, 8*filter_num)\n",
        "\n",
        "\n",
        "  up_3 = upsample_concat(up_2, conv_2)\n",
        "  up_3 = resblock(up_3, 4*filter_num)\n",
        "\n",
        "\n",
        "  up_4 = upsample_concat(up_3, conv_1)\n",
        "  up_4 = resblock(up_4, 2*filter_num)\n",
        "\n",
        "\n",
        "  out = Conv2D(n_classes, (1,1), kernel_initializer='he_normal', padding='same', activation='sigmoid')(up_4)\n",
        "  Res_Unet_with_att_model=Model(Xinput, out)\n",
        "  return Res_Unet_with_att_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSaVjVLEry4d"
      },
      "outputs": [],
      "source": [
        "inputshape = (256,256,3)\n",
        "Res_Unet_model=Res_Unet_model(inputshape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWI5AQRgsakK",
        "outputId": "baa2625d-16e4-4a6e-c0dc-931f3b7cb122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 256, 256, 16  448         ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 256, 256, 16  64         ['conv2d_27[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 256, 256, 16  2320        ['batch_normalization_26[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 256, 256, 16  64         ['conv2d_28[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 16  0          ['batch_normalization_27[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 128, 128, 32  544         ['max_pooling2d_4[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 128, 128, 32  128        ['conv2d_29[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_28[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 128, 128, 32  9248        ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 128, 128, 32  544         ['max_pooling2d_4[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 128, 128, 32  128        ['conv2d_30[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 128, 128, 32  128        ['conv2d_31[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 128, 128, 32  0           ['batch_normalization_29[0][0]', \n",
            "                                )                                 'batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 128, 128, 32  0           ['add_8[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 32)  0           ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 64, 64, 64)   2112        ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 64, 64, 64)  256         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 64, 64, 64)   2112        ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 64, 64, 64)  256         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 64, 64, 64)  256         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 64, 64, 64)   0           ['batch_normalization_32[0][0]', \n",
            "                                                                  'batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 64, 64, 64)   0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 64)  0           ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 32, 32, 128)  8320        ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 32, 32, 128)  512        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 32, 32, 128)  147584      ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 32, 32, 128)  8320        ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 32, 32, 128)  512        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 32, 32, 128)  512        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 32, 32, 128)  0           ['batch_normalization_35[0][0]', \n",
            "                                                                  'batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 32, 32, 128)  0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 128)  0          ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 16, 16, 256)  33024       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 256)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 16, 16, 256)  590080      ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 16, 16, 256)  33024       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_38[0][0]', \n",
            "                                                                  'batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 256)  0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 256)  0          ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 32, 32, 384)  0           ['up_sampling2d_4[0][0]',        \n",
            "                                                                  'activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 32, 32, 128)  49280       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 32, 32, 128)  512        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 32, 32, 128)  147584      ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 32, 32, 128)  49280       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 32, 32, 128)  512        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 32, 32, 128)  512        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 32, 32, 128)  0           ['batch_normalization_41[0][0]', \n",
            "                                                                  'batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 32, 32, 128)  0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 128)  0          ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 64, 64, 192)  0           ['up_sampling2d_5[0][0]',        \n",
            "                                                                  'activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 64, 64, 64)   12352       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 64, 64, 64)  256         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 64, 64, 64)   12352       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 64, 64, 64)  256         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 64, 64, 64)  256         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 64, 64, 64)   0           ['batch_normalization_44[0][0]', \n",
            "                                                                  'batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 64, 64, 64)   0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 64  0          ['activation_27[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 128, 128, 96  0           ['up_sampling2d_6[0][0]',        \n",
            "                                )                                 'activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 128, 128, 32  3104        ['concatenate_6[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 128, 128, 32  128        ['conv2d_47[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_46[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 128, 128, 32  9248        ['activation_28[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 128, 128, 32  3104        ['concatenate_6[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 128, 128, 32  128        ['conv2d_48[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 128, 128, 32  128        ['conv2d_49[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 128, 128, 32  0           ['batch_normalization_47[0][0]', \n",
            "                                )                                 'batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 128, 128, 32  0           ['add_14[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 32  0          ['activation_29[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 256, 256, 48  0           ['up_sampling2d_7[0][0]',        \n",
            "                                )                                 'batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 256, 256, 16  784         ['concatenate_7[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 256, 256, 16  64         ['conv2d_50[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_49[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 256, 256, 16  2320        ['activation_30[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 256, 256, 16  784         ['concatenate_7[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 256, 256, 16  64         ['conv2d_51[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 256, 256, 16  64         ['conv2d_52[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 256, 256, 16  0           ['batch_normalization_50[0][0]', \n",
            "                                )                                 'batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 256, 256, 16  0           ['add_15[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 256, 256, 3)  51          ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,210,547\n",
            "Trainable params: 1,206,163\n",
            "Non-trainable params: 4,384\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "Res_Unet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpcolM-JscYT"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def __init__(self, ids , mask, image_dir = './', batch_size = 16, img_h = 256, img_w = 256, shuffle = True):\n",
        "    self.ids = ids\n",
        "    self.mask = mask\n",
        "    self.image_dir = image_dir\n",
        "    self.batch_size = batch_size\n",
        "    self.img_h = img_h\n",
        "    self.img_w = img_w\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.ids)) / self.batch_size)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    indexes = self.indexes[index* self.batch_size : (index+1) * self.batch_size]\n",
        "    list_ids = [self.ids[i] for i in indexes]\n",
        "    list_mask = [self.mask[i] for i in indexes]\n",
        "    X, y = self.__data_generation(list_ids, list_mask)\n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):    \n",
        "    self.indexes = np.arange(len(self.ids))\n",
        "\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __data_generation(self, list_ids, list_mask):\n",
        "\n",
        "    X = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n",
        "    y = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n",
        "\n",
        "    for i in range(len(list_ids)):\n",
        "      img_path = str(list_ids[i])\n",
        "      mask_path = str(list_mask[i])\n",
        "      img = io.imread(img_path)\n",
        "      mask = io.imread(mask_path)\n",
        "      img = cv2.resize(img,(self.img_h,self.img_w))\n",
        "      img = np.array(img, dtype = np.float64)\n",
        "      mask = cv2.resize(mask,(self.img_h,self.img_w))\n",
        "      mask = np.array(mask, dtype = np.float64)\n",
        "      img -= img.mean()\n",
        "      img /= img.std()\n",
        "      mask -= mask.mean()\n",
        "      mask /= mask.std()\n",
        "      X[i,] = img\n",
        "      y[i,] = mask\n",
        "    y = (y > 0).astype(int)\n",
        "    return X, y\n",
        "\n",
        "train_data = DataGenerator(train_ids, train_mask)\n",
        "val_data = DataGenerator(val_ids, val_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN5vv9BosoqQ"
      },
      "outputs": [],
      "source": [
        "earlystopping = EarlyStopping(monitor='val_loss',\n",
        "                              mode='min', \n",
        "                              verbose=1, \n",
        "                              patience=20\n",
        "                             )\n",
        "checkpointer = ModelCheckpoint(filepath=\"/content/drive/MyDrive/CT_res_unet/CT_res_unet.h5\", \n",
        "                               verbose=1, \n",
        "                               save_best_only=True\n",
        "                              )\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              mode='min',\n",
        "                              verbose=1,\n",
        "                              patience=10,\n",
        "                              min_delta=0.0001,\n",
        "                              factor=0.2\n",
        "                             )\n",
        "filename='/content/drive/MyDrive/CT_res_unet/history.csv'\n",
        "history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuWUL_yatF9E",
        "outputId": "3022ce26-e1a5-4dc5-88c4-e1b7b4a3970a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "adam = tf.keras.optimizers.Adam(lr = 0.01, epsilon = 0.1)\n",
        "Res_Unet_model.compile(optimizer = adam, \n",
        "                  loss = focaltversky, \n",
        "                  metrics = [Recall(), Precision(), tversky, MeanIoU(num_classes=3)]\n",
        "                 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj_RBay2vp2m"
      },
      "outputs": [],
      "source": [
        "Res_Unet_model.load_weights(\"/content/drive/MyDrive/CT_res_unet/CT_res_unet.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pShbWU9wtNqf",
        "outputId": "0a4bf105-986e-4656-a8de-8a7a32750680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - ETA: 0s - loss: 0.1070 - recall_1: 0.9638 - precision_1: 0.9251 - tversky: 0.9465 - mean_io_u_1: 0.8822\n",
            "Epoch 79: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 424ms/step - loss: 0.1070 - recall_1: 0.9638 - precision_1: 0.9251 - tversky: 0.9465 - mean_io_u_1: 0.8822 - val_loss: 0.2156 - val_recall_1: 0.8735 - val_precision_1: 0.8615 - val_tversky: 0.8675 - val_mean_io_u_1: 0.8419 - lr: 8.0000e-05\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1087 - recall_1: 0.9633 - precision_1: 0.9236 - tversky: 0.9457 - mean_io_u_1: 0.8841\n",
            "Epoch 80: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 165s 422ms/step - loss: 0.1087 - recall_1: 0.9633 - precision_1: 0.9236 - tversky: 0.9457 - mean_io_u_1: 0.8841 - val_loss: 0.2165 - val_recall_1: 0.8757 - val_precision_1: 0.8597 - val_tversky: 0.8678 - val_mean_io_u_1: 0.8435 - lr: 8.0000e-05\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1067 - recall_1: 0.9636 - precision_1: 0.9235 - tversky: 0.9470 - mean_io_u_1: 0.8845\n",
            "Epoch 81: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 165s 422ms/step - loss: 0.1067 - recall_1: 0.9636 - precision_1: 0.9235 - tversky: 0.9470 - mean_io_u_1: 0.8845 - val_loss: 0.2098 - val_recall_1: 0.8729 - val_precision_1: 0.8610 - val_tversky: 0.8729 - val_mean_io_u_1: 0.8413 - lr: 8.0000e-05\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1073 - recall_1: 0.9639 - precision_1: 0.9234 - tversky: 0.9466 - mean_io_u_1: 0.8849\n",
            "Epoch 82: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 423ms/step - loss: 0.1073 - recall_1: 0.9639 - precision_1: 0.9234 - tversky: 0.9466 - mean_io_u_1: 0.8849 - val_loss: 0.2154 - val_recall_1: 0.8712 - val_precision_1: 0.8636 - val_tversky: 0.8681 - val_mean_io_u_1: 0.8403 - lr: 8.0000e-05\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1072 - recall_1: 0.9638 - precision_1: 0.9235 - tversky: 0.9464 - mean_io_u_1: 0.8844\n",
            "Epoch 83: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 424ms/step - loss: 0.1072 - recall_1: 0.9638 - precision_1: 0.9235 - tversky: 0.9464 - mean_io_u_1: 0.8844 - val_loss: 0.2124 - val_recall_1: 0.8754 - val_precision_1: 0.8597 - val_tversky: 0.8694 - val_mean_io_u_1: 0.8429 - lr: 8.0000e-05\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1093 - recall_1: 0.9637 - precision_1: 0.9237 - tversky: 0.9448 - mean_io_u_1: 0.8840\n",
            "Epoch 84: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 167s 426ms/step - loss: 0.1093 - recall_1: 0.9637 - precision_1: 0.9237 - tversky: 0.9448 - mean_io_u_1: 0.8840 - val_loss: 0.2159 - val_recall_1: 0.8727 - val_precision_1: 0.8627 - val_tversky: 0.8679 - val_mean_io_u_1: 0.8410 - lr: 8.0000e-05\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1068 - recall_1: 0.9632 - precision_1: 0.9254 - tversky: 0.9472 - mean_io_u_1: 0.8838\n",
            "Epoch 85: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 424ms/step - loss: 0.1068 - recall_1: 0.9632 - precision_1: 0.9254 - tversky: 0.9472 - mean_io_u_1: 0.8838 - val_loss: 0.2089 - val_recall_1: 0.8731 - val_precision_1: 0.8620 - val_tversky: 0.8735 - val_mean_io_u_1: 0.8418 - lr: 8.0000e-05\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1062 - recall_1: 0.9640 - precision_1: 0.9243 - tversky: 0.9475 - mean_io_u_1: 0.8842\n",
            "Epoch 86: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 424ms/step - loss: 0.1062 - recall_1: 0.9640 - precision_1: 0.9243 - tversky: 0.9475 - mean_io_u_1: 0.8842 - val_loss: 0.2204 - val_recall_1: 0.8747 - val_precision_1: 0.8618 - val_tversky: 0.8639 - val_mean_io_u_1: 0.8427 - lr: 8.0000e-05\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1063 - recall_1: 0.9631 - precision_1: 0.9243 - tversky: 0.9475 - mean_io_u_1: 0.8833\n",
            "Epoch 87: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 424ms/step - loss: 0.1063 - recall_1: 0.9631 - precision_1: 0.9243 - tversky: 0.9475 - mean_io_u_1: 0.8833 - val_loss: 0.2203 - val_recall_1: 0.8736 - val_precision_1: 0.8610 - val_tversky: 0.8636 - val_mean_io_u_1: 0.8415 - lr: 8.0000e-05\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1059 - recall_1: 0.9630 - precision_1: 0.9252 - tversky: 0.9474 - mean_io_u_1: 0.8833\n",
            "Epoch 88: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 424ms/step - loss: 0.1059 - recall_1: 0.9630 - precision_1: 0.9252 - tversky: 0.9474 - mean_io_u_1: 0.8833 - val_loss: 0.2049 - val_recall_1: 0.8754 - val_precision_1: 0.8615 - val_tversky: 0.8746 - val_mean_io_u_1: 0.8429 - lr: 8.0000e-05\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1062 - recall_1: 0.9641 - precision_1: 0.9241 - tversky: 0.9476 - mean_io_u_1: 0.8845\n",
            "Epoch 89: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 165s 422ms/step - loss: 0.1062 - recall_1: 0.9641 - precision_1: 0.9241 - tversky: 0.9476 - mean_io_u_1: 0.8845 - val_loss: 0.2143 - val_recall_1: 0.8724 - val_precision_1: 0.8611 - val_tversky: 0.8697 - val_mean_io_u_1: 0.8416 - lr: 8.0000e-05\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1054 - recall_1: 0.9637 - precision_1: 0.9245 - tversky: 0.9481 - mean_io_u_1: 0.8844\n",
            "Epoch 90: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 425ms/step - loss: 0.1054 - recall_1: 0.9637 - precision_1: 0.9245 - tversky: 0.9481 - mean_io_u_1: 0.8844 - val_loss: 0.2004 - val_recall_1: 0.8743 - val_precision_1: 0.8616 - val_tversky: 0.8791 - val_mean_io_u_1: 0.8421 - lr: 8.0000e-05\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1082 - recall_1: 0.9634 - precision_1: 0.9247 - tversky: 0.9460 - mean_io_u_1: 0.8836\n",
            "Epoch 91: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 165s 423ms/step - loss: 0.1082 - recall_1: 0.9634 - precision_1: 0.9247 - tversky: 0.9460 - mean_io_u_1: 0.8836 - val_loss: 0.2196 - val_recall_1: 0.8731 - val_precision_1: 0.8609 - val_tversky: 0.8653 - val_mean_io_u_1: 0.8415 - lr: 8.0000e-05\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1067 - recall_1: 0.9638 - precision_1: 0.9246 - tversky: 0.9467 - mean_io_u_1: 0.8843\n",
            "Epoch 92: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 424ms/step - loss: 0.1067 - recall_1: 0.9638 - precision_1: 0.9246 - tversky: 0.9467 - mean_io_u_1: 0.8843 - val_loss: 0.2112 - val_recall_1: 0.8737 - val_precision_1: 0.8602 - val_tversky: 0.8708 - val_mean_io_u_1: 0.8423 - lr: 8.0000e-05\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1082 - recall_1: 0.9640 - precision_1: 0.9248 - tversky: 0.9457 - mean_io_u_1: 0.8849\n",
            "Epoch 93: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 424ms/step - loss: 0.1082 - recall_1: 0.9640 - precision_1: 0.9248 - tversky: 0.9457 - mean_io_u_1: 0.8849 - val_loss: 0.2019 - val_recall_1: 0.8751 - val_precision_1: 0.8601 - val_tversky: 0.8773 - val_mean_io_u_1: 0.8430 - lr: 8.0000e-05\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1065 - recall_1: 0.9636 - precision_1: 0.9245 - tversky: 0.9473 - mean_io_u_1: 0.8845\n",
            "Epoch 94: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 423ms/step - loss: 0.1065 - recall_1: 0.9636 - precision_1: 0.9245 - tversky: 0.9473 - mean_io_u_1: 0.8845 - val_loss: 0.2203 - val_recall_1: 0.8731 - val_precision_1: 0.8626 - val_tversky: 0.8638 - val_mean_io_u_1: 0.8421 - lr: 8.0000e-05\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1031 - recall_1: 0.9640 - precision_1: 0.9246 - tversky: 0.9495 - mean_io_u_1: 0.8846\n",
            "Epoch 95: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 423ms/step - loss: 0.1031 - recall_1: 0.9640 - precision_1: 0.9246 - tversky: 0.9495 - mean_io_u_1: 0.8846 - val_loss: 0.2129 - val_recall_1: 0.8743 - val_precision_1: 0.8626 - val_tversky: 0.8690 - val_mean_io_u_1: 0.8440 - lr: 8.0000e-05\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1041 - recall_1: 0.9635 - precision_1: 0.9250 - tversky: 0.9494 - mean_io_u_1: 0.8846\n",
            "Epoch 96: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 166s 425ms/step - loss: 0.1041 - recall_1: 0.9635 - precision_1: 0.9250 - tversky: 0.9494 - mean_io_u_1: 0.8846 - val_loss: 0.2040 - val_recall_1: 0.8823 - val_precision_1: 0.8619 - val_tversky: 0.8783 - val_mean_io_u_1: 0.8471 - lr: 8.0000e-05\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1035 - recall_1: 0.9643 - precision_1: 0.9243 - tversky: 0.9498 - mean_io_u_1: 0.8854\n",
            "Epoch 97: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 165s 421ms/step - loss: 0.1035 - recall_1: 0.9643 - precision_1: 0.9243 - tversky: 0.9498 - mean_io_u_1: 0.8854 - val_loss: 0.2189 - val_recall_1: 0.8736 - val_precision_1: 0.8625 - val_tversky: 0.8646 - val_mean_io_u_1: 0.8423 - lr: 8.0000e-05\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1059 - recall_1: 0.9642 - precision_1: 0.9252 - tversky: 0.9478 - mean_io_u_1: 0.8844\n",
            "Epoch 98: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 165s 423ms/step - loss: 0.1059 - recall_1: 0.9642 - precision_1: 0.9252 - tversky: 0.9478 - mean_io_u_1: 0.8844 - val_loss: 0.2203 - val_recall_1: 0.8723 - val_precision_1: 0.8610 - val_tversky: 0.8639 - val_mean_io_u_1: 0.8427 - lr: 8.0000e-05\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1068 - recall_1: 0.9635 - precision_1: 0.9249 - tversky: 0.9469 - mean_io_u_1: 0.8843\n",
            "Epoch 99: val_loss did not improve from 0.20039\n",
            "391/391 [==============================] - 165s 423ms/step - loss: 0.1068 - recall_1: 0.9635 - precision_1: 0.9249 - tversky: 0.9469 - mean_io_u_1: 0.8843 - val_loss: 0.2033 - val_recall_1: 0.8755 - val_precision_1: 0.8643 - val_tversky: 0.8774 - val_mean_io_u_1: 0.8459 - lr: 8.0000e-05\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1044 - recall_1: 0.9639 - precision_1: 0.9245 - tversky: 0.9492 - mean_io_u_1: 0.8850\n",
            "Epoch 100: val_loss did not improve from 0.20039\n",
            "\n",
            "Epoch 100: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
            "391/391 [==============================] - 165s 423ms/step - loss: 0.1044 - recall_1: 0.9639 - precision_1: 0.9245 - tversky: 0.9492 - mean_io_u_1: 0.8850 - val_loss: 0.2177 - val_recall_1: 0.8736 - val_precision_1: 0.8612 - val_tversky: 0.8654 - val_mean_io_u_1: 0.8429 - lr: 8.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f43d70cf710>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "Res_Unet_model.fit(train_data, \n",
        "                  epochs = 100,\n",
        "                  initial_epoch=78,\n",
        "                  validation_data = val_data,\n",
        "                  callbacks = [checkpointer, earlystopping, reduce_lr,history_logger]\n",
        "                 )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "unetrandom.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}